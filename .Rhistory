s(subject_id, bs = "re") +
s(question, bs = "re"),
data    = chunks_long,
method  = "fREML"
)
summary(gam_model)
gam.check(gam_model)
appraise(gam_model)
newdata <- expand.grid(
norm_mid              = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long$deliberation_function),
response              = levels(chunks_long$response),
accuracy_high         = levels(chunks_long$accuracy_high)
)
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]
predictions <- predict(
gam_model,
newdata = newdata,
se.fit  = TRUE,
type    = "response",
exclude = c("s(subject_id)", "s(question)")
)
newdata <- newdata %>%
mutate(
pred = predictions$fit,
se   = predictions$se.fit
)
newdata$diff <- NA
newdata$pval <- NA
for (f in unique(newdata$deliberation_function)) {
for (a in unique(newdata$accuracy_high)) {
for (pos in unique(newdata$norm_mid)) {
tmp <- newdata %>%
filter(deliberation_function == f,
accuracy_high == a,
norm_mid == pos)
d  <- tmp$pred[tmp$response == "Correct"] - tmp$pred[tmp$response == "Incorrect"]
se <- sqrt(tmp$se[tmp$response == "Correct"]^2 +
tmp$se[tmp$response == "Incorrect"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff[newdata$deliberation_function == f &
newdata$accuracy_high == a &
newdata$norm_mid == pos] <- d
newdata$pval[newdata$deliberation_function == f &
newdata$accuracy_high == a &
newdata$norm_mid == pos] <- pval
}
}
}
newdata <- newdata %>%
group_by(deliberation_function, accuracy_high) %>%
mutate(pval_adj = p.adjust(pval, method = "fdr"),
significant = pval_adj < 0.05) %>%
ungroup()
signif_regions <- newdata %>%
arrange(deliberation_function, accuracy_high, norm_mid) %>%
group_by(deliberation_function, accuracy_high) %>%
mutate(sig_grp = rleid(significant)) %>%
filter(significant) %>%
group_by(deliberation_function, accuracy_high, sig_grp) %>%
summarise(
xmin = min(norm_mid),
xmax = max(norm_mid),
.groups = "drop"
)
p_final <- ggplot() +
geom_line(data = newdata,
aes(x = norm_mid, y = pred, color = response),
linewidth = 1) +
geom_ribbon(data = newdata,
aes(x = norm_mid,
ymin = pred - 1.96 * se,
ymax = pred + 1.96 * se,
fill = response),
alpha = 0.2, color = NA) +
geom_rect(data = signif_regions,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "grey30", alpha = 0.1) +
facet_grid(accuracy_high ~ deliberation_function) +
scale_color_manual(values = c("Correct" = "forestgreen", "Incorrect" = "tomato3")) +
scale_fill_manual(values  = c("Correct" = "forestgreen", "Incorrect" = "tomato3")) +
theme_apa() +
labs(
x = "Normalized Position in Verbalization",
y = "Predicted Score",
color = "Response Type",
fill  = "Response Type"
)
ggsave("./Output/gam_trajectory_by_accuracy_and_function.png",
p_final, dpi = 600, width = 14, height = 9)
p_final
newdata$diff_highlow    <- NA
newdata$pval_highlow    <- NA
newdata$se_diff_highlow <- NA  # <- add this line
for (f in unique(newdata$deliberation_function)) {
for (r in unique(newdata$response)) {
for (pos in unique(newdata$norm_mid)) {
tmp <- newdata %>%
filter(deliberation_function == f,
response == r,
norm_mid == pos)
d  <- tmp$pred[tmp$accuracy_high == "High"] - tmp$pred[tmp$accuracy_high == "Low"]
se <- sqrt(tmp$se[tmp$accuracy_high == "High"]^2 +
tmp$se[tmp$accuracy_high == "Low"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff_highlow[newdata$deliberation_function == f &
newdata$response == r &
newdata$norm_mid == pos] <- d
newdata$se_diff_highlow[newdata$deliberation_function == f &
newdata$response == r &
newdata$norm_mid == pos] <- se
newdata$pval_highlow[newdata$deliberation_function == f &
newdata$response == r &
newdata$norm_mid == pos] <- pval
}
}
}
newdata <- newdata %>%
group_by(deliberation_function, response) %>%
mutate(pval_highlow_adj = p.adjust(pval_highlow, method = "fdr"),
significant_highlow = pval_highlow_adj < 0.05) %>%
ungroup()
signif_regions_highlow <- newdata %>%
arrange(deliberation_function, response, norm_mid) %>%
group_by(deliberation_function, response) %>%
mutate(sig_grp = rleid(significant_highlow)) %>%
filter(significant_highlow) %>%
group_by(deliberation_function, response, sig_grp) %>%
summarise(xmin = min(norm_mid),
xmax = max(norm_mid),
.groups = "drop")
p_diff <- ggplot() +
geom_hline(yintercept = 0, linetype = "dashed", color = "gray40") +
# Confidence ribbon
geom_ribbon(data = newdata %>% distinct(deliberation_function, response, norm_mid, .keep_all = TRUE),
aes(x = norm_mid,
ymin = diff_highlow - 1.96 * se_diff_highlow,
ymax = diff_highlow + 1.96 * se_diff_highlow),
fill = "black", alpha = 0.15) +
# Difference line
geom_line(data = newdata %>% distinct(deliberation_function, response, norm_mid, .keep_all = TRUE),
aes(x = norm_mid, y = diff_highlow),
color = "black", linewidth = 1) +
# Significance regions
geom_rect(data = signif_regions_highlow,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "steelblue", alpha = 0.2) +
facet_grid(response ~ deliberation_function) +
theme_apa() +
labs(
x = "Normalized Position in Verbalization",
y = "Difference (High - Low Accuracy)",
title = "Accuracy Group Differences per Response & Deliberation Function"
)
ggsave("./Output/gam_contrast_high_vs_low_accuracy.png",
p_diff, dpi = 600, width = 14, height = 9)
p_diff
ggsave("./Output/gam_contrast_high_vs_low_accuracy.png",
p_diff, dpi = 600, width = 14, height = 9)
p_diff
# ──────────────────────────────────────────────────────────────
# Full Pipeline: Uncertainty (n−1, n−2) → Deliberation Functions
# ──────────────────────────────────────────────────────────────
# Load libraries
library(mgcv)
library(emmeans)
library(knitr)
library(kableExtra)
library(broom)
library(stringr)
# Step 1: Add uncertainty and lag variables
chunks_scored <- chunks_scored %>%
mutate(response_uncertainty = 100 - response_confidence) %>%
arrange(subject_id, question, chunk_id) %>%
group_by(subject_id, question) %>%
mutate(
prev_uncertainty  = lag(response_uncertainty, 1),
prev2_uncertainty = lag(response_uncertainty, 2)
) %>%
ungroup()
# Step 2: Long format for 4 functions
chunks_long <- chunks_scored %>%
pivot_longer(
cols = c("response_control", "response_generation",
"response_justification", "response_regulation"),
names_to = "deliberation_function",
values_to = "score"
) %>%
mutate(
deliberation_function = recode_factor(
deliberation_function,
"response_control"       = "Control",
"response_generation"    = "Generation",
"response_justification" = "Justification",
"response_regulation"    = "Regulation"
),
chunk_id = as.numeric(chunk_id))
gam_linear <- bam(
score ~ deliberation_function * prev_uncertainty +
deliberation_function * prev2_uncertainty +
s(norm_mid, k = 6) +
s(subject_id, bs = "re") +
s(question,   bs = "re"),
data = chunks_long,
method = "fREML"
)
gam_smooth <- bam(
score ~ deliberation_function +
s(prev_uncertainty,  by = deliberation_function, k = 6) +
s(prev2_uncertainty, by = deliberation_function, k = 6) +
s(norm_mid, k = 6) +
s(subject_id, bs = "re") +
s(question,   bs = "re"),
data = chunks_long,
method = "fREML"
)
AIC(gam_linear, gam_smooth)
gam_smooth <- bam(
score ~ deliberation_function * prev_uncertainty +  # linear
s(prev_uncertainty, by = deliberation_function, k = 6) +  # smooth
deliberation_function * prev2_uncertainty +
s(prev2_uncertainty, by = deliberation_function, k = 6) +
s(norm_mid, k = 6) +
s(subject_id, bs = "re") +
s(question, bs = "re"),
data = chunks_long,
method = "fREML"
)
# Step 3B: Summary of smooth terms (edf, F, p)
gam_summary_tbl <- tidy(gam_smooth, parametric = FALSE) %>%
filter(str_detect(term, "prev_uncertainty|prev2_uncertainty")) %>%
mutate(
signif = case_when(
p.value < 0.001 ~ "***",
p.value < 0.01  ~ "**",
p.value < 0.05  ~ "*",
p.value < 0.1   ~ ".",
TRUE            ~ ""
)
) %>%
select(Smooth = term, EDF = edf, F = statistic, `p-value` = p.value, signif)
gam_summary_tbl %>%
kable(digits = 3, caption = "Smooth Terms from GAMM: Nonlinear Effects of Uncertainty") %>%
kable_styling(full_width = FALSE)
# ──────────────────────────────────────────────────────────────
#  Linear-slope part of the semi-parametric model  (emtrends)
# ──────────────────────────────────────────────────────────────
library(emmeans)
## ---------- 1. Average marginal slopes (n−1) ----------
em_n1 <- emtrends(gam_smooth,
specs = ~ deliberation_function,   # one slope per function
var   = "prev_uncertainty")        # linear term
n1_tbl <- summary(em_n1, infer = TRUE) |>
mutate(signif = case_when(
p.value < .001 ~ "***",
p.value < .01  ~ "**",
p.value < .05  ~ "*",
p.value < .10  ~ ".",
TRUE           ~ "")) |>
select(Function = deliberation_function,
Slope    = prev_uncertainty.trend,
SE       = SE,
t        = df,
`p-value`= p.value,
signif)
# Pairwise differences in those slopes
n1_pairs <- pairs(em_n1) |>
summary(infer = TRUE, adjust = "fdr")
## ---------- 2. Average marginal slopes (n−2) ----------
em_n2 <- emtrends(gam_smooth,
specs = ~ deliberation_function,
var   = "prev2_uncertainty")
n2_tbl <- summary(em_n2, infer = TRUE) |>
mutate(signif = case_when(
p.value < .001 ~ "***",
p.value < .01  ~ "**",
p.value < .05  ~ "*",
p.value < .10  ~ ".",
TRUE           ~ "")) |>
select(Function = deliberation_function,
Slope    = prev2_uncertainty.trend,
SE       = SE,
t        = df,
`p-value`= p.value,
signif)
n2_pairs <- pairs(em_n2) |>
summary(infer = TRUE, adjust = "fdr")
## ---------- 3. Nice tables ----------
library(knitr); library(kableExtra)
kable(n1_tbl, digits = 3,
caption = "Linear Slopes of Uncertainty at chunk n−1 (from `gam_smooth`)") |>
kable_styling(full_width = FALSE)
kable(n2_tbl, digits = 3,
caption = "Linear Slopes of Uncertainty at chunk n−2 (from `gam_smooth`)") |>
kable_styling(full_width = FALSE)
kable(n1_pairs, digits = 3,
caption = "Pairwise Differences of n−1 Slopes (FDR-corrected)") |>
kable_styling(full_width = FALSE)
kable(n2_pairs, digits = 3,
caption = "Pairwise Differences of n−2 Slopes (FDR-corrected)") |>
kable_styling(full_width = FALSE)
# Step 5A: Plot effect of prev_uncertainty (n−1)
one_id <- chunks_long$subject_id[!is.na(chunks_long$subject_id)][1]
one_q  <- chunks_long$question[!is.na(chunks_long$question)][1]
rng1 <- range(chunks_long$prev_uncertainty, na.rm = TRUE)
newd1 <- expand.grid(
prev_uncertainty       = seq(rng1[1], rng1[2], length.out = 100),
prev2_uncertainty      = median(chunks_long$prev2_uncertainty, na.rm = TRUE),
deliberation_function  = levels(chunks_long$deliberation_function),
norm_mid               = 0.5,
subject_id             = one_id,
question               = one_q
)
preds1 <- predict(gam_smooth, newdata = newd1, se.fit = TRUE)
newd1$fit <- preds1$fit
newd1$se  <- preds1$se.fit
newd1$upr <- newd1$fit + 1.96 * newd1$se
newd1$lwr <- newd1$fit - 1.96 * newd1$se
ggplot(newd1, aes(prev_uncertainty, fit,
colour = deliberation_function,
fill = deliberation_function)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .15, colour = NA) +
geom_line(size = 1) +
labs(x = "Uncertainty at chunk n−1",
y = "Predicted score at chunk n",
title = "Effect of Uncertainty at Chunk n−1",
colour = "Deliberation\nFunction",
fill   = "Deliberation\nFunction") +
theme_minimal(base_size = 13)
# Step 5B: Plot effect of prev2_uncertainty (n−2)
rng2 <- range(chunks_long$prev2_uncertainty, na.rm = TRUE)
newd2 <- expand.grid(
prev2_uncertainty      = seq(rng2[1], rng2[2], length.out = 100),
prev_uncertainty       = median(chunks_long$prev_uncertainty, na.rm = TRUE),
deliberation_function  = levels(chunks_long$deliberation_function),
norm_mid               = 0.5,
subject_id             = one_id,
question               = one_q
)
preds2 <- predict(gam_smooth, newdata = newd2, se.fit = TRUE)
newd2$fit <- preds2$fit
newd2$se  <- preds2$se.fit
newd2$upr <- newd2$fit + 1.96 * newd2$se
newd2$lwr <- newd2$fit - 1.96 * newd2$se
ggplot(newd2, aes(prev2_uncertainty, fit,
colour = deliberation_function,
fill = deliberation_function)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .15, colour = NA) +
geom_line(size = 1) +
labs(x = "Uncertainty at chunk n−2",
y = "Predicted score at chunk n",
title = "Effect of Uncertainty at Chunk n−2",
colour = "Deliberation\nFunction",
fill   = "Deliberation\nFunction") +
theme_minimal(base_size = 13)
# Step 6: Heatmap of n−1 × n−2 effects
grid <- expand.grid(
prev_uncertainty       = seq(rng1[1], rng1[2], length.out = 50),
prev2_uncertainty      = seq(rng2[1], rng2[2], length.out = 50),
deliberation_function  = levels(chunks_long$deliberation_function),
norm_mid               = 0.5,
subject_id             = one_id,
question               = one_q
)
preds_grid <- predict(gam_smooth, newdata = grid, se.fit = TRUE)
grid$fit <- preds_grid$fit
ggplot(grid, aes(x = prev_uncertainty, y = prev2_uncertainty, fill = fit)) +
geom_tile() +
scale_fill_gradient2(
low = "green3", mid = "white", high = "red3",
midpoint = mean(grid$fit, na.rm = TRUE),
name = "Predicted\nscore"
) +
facet_wrap(~ deliberation_function, ncol = 2) +
labs(
title = "Predicted Deliberation Score by Combined Uncertainty (n−1 × n−2)",
x = "Uncertainty at chunk n−1",
y = "Uncertainty at chunk n−2"
) +
theme_minimal(base_size = 13) +
theme(
strip.text = element_text(face = "bold"),
legend.title = element_text(face = "bold"),
panel.grid = element_blank()
)
# ----------------------------------------------------------------------------
# Recoding for clarity
# ----------------------------------------------------------------------------
chunks_long_lure <- chunks_long %>%
mutate(
lure_consideration = factor(lure_consideration,
levels = c(0, 1),
labels = c("Lure Non-Considered", "Lure Considered")),
deliberation_function = factor(deliberation_function),
response              = factor(response),
subject_id            = factor(subject_id),
question              = factor(question)
) %>%
filter(lure_consideration %in% c("Lure Non-Considered", "Lure Considered"),
response %in% c("Correct", "Incorrect"))
# ----------------------------------------------------------------------------
# Model (as you did)
# ----------------------------------------------------------------------------
gam_model <- bam(
score ~ lure_consideration * response * deliberation_function +
s(norm_mid, by = interaction(lure_consideration, response, deliberation_function), k = 10) +
s(subject_id, bs = "re") +
s(question, bs = "re"),
data = chunks_long_lure,
method = "fREML"
)
summary(gam_model)
gam.check(gam_model)
appraise(gam_model)
# ----------------------------------------------------------------------------
# Generate Prediction Data
# ----------------------------------------------------------------------------
newdata <- expand.grid(
norm_mid = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long_lure$deliberation_function),
response = levels(chunks_long_lure$response),
lure_consideration = levels(chunks_long_lure$lure_consideration)
)
newdata$subject_id <- levels(chunks_long_lure$subject_id)[1]
newdata$question   <- levels(chunks_long_lure$question)[1]
predictions <- predict(
gam_model,
newdata = newdata,
se.fit = TRUE,
exclude = c("s(subject_id)", "s(question)")
)
newdata$pred <- predictions$fit
newdata$se   <- predictions$se.fit
# ----------------------------------------------------------------------------
# Compute Pairwise Differences: Lure vs No Lure
# ----------------------------------------------------------------------------
newdata$diff <- NA
newdata$pval <- NA
for(df in unique(newdata$deliberation_function)) {
for(resp in unique(newdata$response)) {
for(pos in unique(newdata$normalized_position)) {
tmp <- newdata %>%
filter(deliberation_function == df,
response == resp,
normalized_position == pos)
d  <- tmp$pred[tmp$lure_consideration == "Lure Considered"] -
tmp$pred[tmp$lure_consideration == "Lure Non-Considered"]
se <- sqrt(tmp$se[tmp$lure_consideration == "Lure Considered"]^2 +
tmp$se[tmp$lure_consideration == "Lure Non-Considered"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff[newdata$deliberation_function == df &
newdata$response == resp &
newdata$normalized_position == pos] <- d
newdata$pval[newdata$deliberation_function == df &
newdata$response == resp &
newdata$normalized_position == pos] <- pval
}
}
}
newdata <- newdata %>%
group_by(deliberation_function, response) %>%
mutate(pval_adj = p.adjust(pval, method = "fdr"),
significant = pval_adj < 0.05) %>%
ungroup()
newdata$significant <- newdata$pval_adj < 0.05
# ----------------------------------------------------------------------------
# Significant Regions
# ----------------------------------------------------------------------------
signif_regions <- newdata %>%
arrange(deliberation_function, response, norm_mid) %>%
group_by(deliberation_function, response) %>%
mutate(sig_grp = data.table::rleid(significant)) %>%
filter(significant) %>%
group_by(deliberation_function, response, sig_grp) %>%
summarise(xmin = min(norm_mid),
xmax = max(norm_mid)) %>%
ungroup()
# ----------------------------------------------------------------------------
# Plot
# ----------------------------------------------------------------------------
p_final <- ggplot() +
geom_line(data = newdata,
aes(x = norm_mid, y = pred,
color = lure_consideration),
size = 1) +
geom_ribbon(data = newdata,
aes(x = norm_mid, ymin = pred - 1.96 * se, ymax = pred + 1.96 * se,
fill = lure_consideration),
alpha = 0.2, color = NA) +
geom_rect(data = signif_regions,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "grey30", alpha = 0.1) +
facet_grid(response ~ deliberation_function) +
scale_color_manual(values = c("Lure Non-Considered" = "forestgreen",
"Lure Considered"   = "tomato3")) +
scale_fill_manual(values = c("Lure Non-Considered" = "forestgreen",
"Lure Considered"   = "tomato3")) +
theme_apa() +
labs(x = "Normalized Position in Verbalization",
y = "Predicted Score",
color = "Lure Consideration",
fill  = "Lure Consideration")
p_final
# ----------------------------------------------------------------------------
# Save
# ----------------------------------------------------------------------------
ggsave("./Output/gam_trajectory_lure_vs_no_lure_per_response_and_function.png",
p_final, dpi = 600, width = 12, height = 8)
