predictions <- predict(
gam_model,
newdata = newdata,
se.fit = TRUE,
exclude = c("s(subject_id)", "s(question)")
)
newdata$pred <- predictions$fit
newdata$se   <- predictions$se.fit
# ----------------------------------------------------------------------------
# Compute Pairwise Differences with z-test
# ----------------------------------------------------------------------------
newdata$diff <- NA
newdata$pval <- NA
for(f in unique(newdata$deliberation_function)) {
for(pos in unique(newdata$normalized_position)) {
tmp <- newdata %>%
filter(deliberation_function == f, normalized_position == pos)
d  <- tmp$pred[tmp$accuracy_high == "High"] - tmp$pred[tmp$accuracy_high == "Low"]
se <- sqrt(tmp$se[tmp$accuracy_high == "High"]^2 + tmp$se[tmp$accuracy_high == "Low"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff[newdata$deliberation_function == f & newdata$normalized_position == pos] <- d
newdata$pval[newdata$deliberation_function == f & newdata$normalized_position == pos] <- pval
}
}
# ----------------------------------------------------------------------------
# Multiple Comparisons Correction
# ----------------------------------------------------------------------------
newdata <- newdata %>%
group_by(deliberation_function) %>%
mutate(pval_adj = p.adjust(pval, method = "fdr"),
significant = pval_adj < 0.05) %>%
ungroup()
# ----------------------------------------------------------------------------
# Identify Significant Contiguous Regions
# ----------------------------------------------------------------------------
signif_regions <- newdata %>%
arrange(deliberation_function, normalized_position) %>%
group_by(deliberation_function) %>%
mutate(sig_grp = rleid(significant)) %>%
filter(significant) %>%
group_by(deliberation_function, sig_grp) %>%
summarise(xmin = min(normalized_position),
xmax = max(normalized_position)) %>%
ungroup()
# ----------------------------------------------------------------------------
# Plot: Faceted Smooth Trajectories with Significance Zones
# ----------------------------------------------------------------------------
p_final <- ggplot() +
# GAM Fit Lines
geom_line(data = newdata,
aes(x = normalized_position, y = pred, color = accuracy_high),
size = 1) +
# GAM Confidence Ribbons
geom_ribbon(data = newdata,
aes(x = normalized_position, ymin = pred - 1.96 * se, ymax = pred + 1.96 * se, fill = accuracy_high),
alpha = 0.2, color = NA) +
# Significance Highlighting
geom_rect(data = signif_regions,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "grey30", alpha = 0.1) +
facet_wrap(~deliberation_function, ncol = 2) +
scale_color_manual(values = c("Low" = "tomato3", "High" = "forestgreen")) +
scale_fill_manual(values = c("Low" = "tomato3", "High" = "forestgreen")) +
theme_apa() +
labs(x = "Normalized Position in Verbalization",
y = "Predicted Score",
color = "Accuracy Group",
fill  = "Accuracy Group")
p_final
# ----------------------------------------------------------------------------
# Save Plot
# ----------------------------------------------------------------------------
ggsave("./Output/gam_trajectory_per_accuracy_and_function.png",
p_final, dpi = 600, width = 12, height = 8)
# ----------------------------------------------------------------------------
# Fit GAM Model with Beta family and Random Effects (Including accuracy_high)
# ----------------------------------------------------------------------------
gam_model <- bam(
score ~ accuracy_high * response * deliberation_function +
s(normalized_position, by = interaction(accuracy_high, response, deliberation_function), k = 10) +
s(subject_id, bs = "re") +
s(question, bs = "re"),
data = chunks_long,
method = "fREML"
)
summary(gam_model)
# ----------------------------------------------------------------------------
# Diagnostics
# ----------------------------------------------------------------------------
gam.check(gam_model)
appraise(gam_model)
# ----------------------------------------------------------------------------
# Generate New Data for Predictions
# ----------------------------------------------------------------------------
newdata <- expand.grid(
normalized_position = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long$deliberation_function),
response = levels(chunks_long$response),
accuracy_high = levels(chunks_long$accuracy_high)
)
# Add dummy subject_id and question for prediction
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]
# Predict ignoring random effects
predictions <- predict(
gam_model,
newdata = newdata,
se.fit = TRUE,
exclude = c("s(subject_id)", "s(question)")
)
newdata$pred <- predictions$fit
newdata$se   <- predictions$se.fit
# ----------------------------------------------------------------------------
# Compute Pairwise Differences with z-test per accuracy_high
# ----------------------------------------------------------------------------
newdata$diff <- NA
newdata$pval <- NA
for(f in unique(newdata$deliberation_function)) {
for(a in unique(newdata$accuracy_high)) {
for(pos in unique(newdata$normalized_position)) {
tmp <- newdata %>%
filter(deliberation_function == f,
accuracy_high == a,
normalized_position == pos)
d  <- tmp$pred[tmp$response == "Correct"] - tmp$pred[tmp$response == "Incorrect"]
se <- sqrt(tmp$se[tmp$response == "Correct"]^2 + tmp$se[tmp$response == "Incorrect"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff[newdata$deliberation_function == f &
newdata$accuracy_high == a &
newdata$normalized_position == pos] <- d
newdata$pval[newdata$deliberation_function == f &
newdata$accuracy_high == a &
newdata$normalized_position == pos] <- pval
}
}
}
# ----------------------------------------------------------------------------
# FDR Correction
# ----------------------------------------------------------------------------
newdata <- newdata %>%
group_by(deliberation_function, accuracy_high) %>%
mutate(pval_adj = p.adjust(pval, method = "fdr"),
significant = pval_adj < 0.05) %>%
ungroup()
# ----------------------------------------------------------------------------
# Observed Means for Overlay
# ----------------------------------------------------------------------------
observed_means <- chunks_long %>%
group_by(deliberation_function, response, accuracy_high, normalized_position) %>%
summarise(
mean_score = mean(score, na.rm = TRUE),
se_score   = sd(score, na.rm = TRUE) / sqrt(n())
) %>%
ungroup()
# ----------------------------------------------------------------------------
# Identify Significant Contiguous Regions
# ----------------------------------------------------------------------------
signif_regions <- newdata %>%
arrange(deliberation_function, accuracy_high, normalized_position) %>%
group_by(deliberation_function, accuracy_high) %>%
mutate(sig_grp = rleid(significant)) %>%
filter(significant) %>%
group_by(deliberation_function, accuracy_high, sig_grp) %>%
summarise(xmin = min(normalized_position),
xmax = max(normalized_position)) %>%
ungroup()
# ----------------------------------------------------------------------------
# Plot: Faceted Smooth Trajectories with Significance Zones
# ----------------------------------------------------------------------------
p_final <- ggplot() +
# GAM Fit Lines
geom_line(data = newdata,
aes(x = normalized_position, y = pred, color = response),
size = 1) +
# GAM CI
geom_ribbon(data = newdata,
aes(x = normalized_position, ymin = pred - 1.96 * se, ymax = pred + 1.96 * se, fill = response),
alpha = 0.2, color = NA) +
# Significance Zones
geom_rect(data = signif_regions,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "grey30", alpha = 0.1) +
facet_grid(accuracy_high ~ deliberation_function) +
scale_color_manual(values = c("Correct" = "forestgreen",
"Incorrect" = "tomato3")) +
scale_fill_manual(values = c("Correct" = "forestgreen",
"Incorrect" = "tomato3")) +
theme_apa() +
labs(x = "Normalized Position in Verbalization",
y = "Predicted Score",
color = "Response Type",
fill = "Response Type")
p_final
# ----------------------------------------------------------------------------
# Save Plot
# ----------------------------------------------------------------------------
ggsave("./Output/gam_trajectory_by_accuracy_and_function.png",
p_final, dpi = 600, width = 14, height = 9)
# ----------------------------------------------------------------------------
# Compute Pairwise Differences: High vs Low for Each Response Level
# ----------------------------------------------------------------------------
newdata$diff_highlow <- NA
newdata$pval_highlow <- NA
for(f in unique(newdata$deliberation_function)) {
for(r in unique(newdata$response)) {
for(pos in unique(newdata$normalized_position)) {
tmp <- newdata %>%
filter(deliberation_function == f,
response == r,
normalized_position == pos)
d  <- tmp$pred[tmp$accuracy_high == "High"] - tmp$pred[tmp$accuracy_high == "Low"]
se <- sqrt(tmp$se[tmp$accuracy_high == "High"]^2 + tmp$se[tmp$accuracy_high == "Low"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff_highlow[newdata$deliberation_function == f &
newdata$response == r &
newdata$normalized_position == pos] <- d
newdata$pval_highlow[newdata$deliberation_function == f &
newdata$response == r &
newdata$normalized_position == pos] <- pval
}
}
}
# ----------------------------------------------------------------------------
# FDR Correction for High vs Low Differences
# ----------------------------------------------------------------------------
newdata <- newdata %>%
group_by(deliberation_function, response) %>%
mutate(pval_highlow_adj = p.adjust(pval_highlow, method = "fdr"),
significant_highlow = pval_highlow_adj < 0.05) %>%
ungroup()
# ----------------------------------------------------------------------------
# Identify Significant Contiguous Regions: High vs Low
# ----------------------------------------------------------------------------
signif_regions_highlow <- newdata %>%
arrange(deliberation_function, response, normalized_position) %>%
group_by(deliberation_function, response) %>%
mutate(sig_grp = rleid(significant_highlow)) %>%
filter(significant_highlow) %>%
group_by(deliberation_function, response, sig_grp) %>%
summarise(xmin = min(normalized_position),
xmax = max(normalized_position)) %>%
ungroup()
# ----------------------------------------------------------------------------
# Plot: Accuracy Group Differences per Function and Response
# ----------------------------------------------------------------------------
p_diff <- ggplot() +
geom_hline(yintercept = 0, linetype = "dashed", color = "gray40") +
# Difference Line
geom_line(data = newdata %>% distinct(deliberation_function, response, accuracy_high, normalized_position, .keep_all = TRUE),
aes(x = normalized_position, y = diff_highlow),
color = "black", linewidth = 1) +
# Confidence Ribbon (optional, if estimating CI)
# geom_ribbon(aes(ymin = diff_highlow - 1.96 * se_combined,
#                 ymax = diff_highlow + 1.96 * se_combined),
#             alpha = 0.15, fill = "black") +
# Significance Regions
geom_rect(data = signif_regions_highlow,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "steelblue", alpha = 0.2) +
facet_grid(response ~ deliberation_function) +
theme_apa() +
labs(
x = "Normalized Position in Verbalization",
y = "Difference (High - Low Accuracy)",
title = "Accuracy Group Differences per Response & Deliberation Function"
)
p_diff
# ----------------------------------------------------------------------------
# Save Plot
# ----------------------------------------------------------------------------
ggsave("./Output/gam_contrast_high_vs_low_accuracy.png",
p_diff, dpi = 600, width = 14, height = 9)
# ----------------------------------------------------------------------------
# Recoding for clarity
# ----------------------------------------------------------------------------
chunks_long_lure <- chunks_long %>%
mutate(
lure_consideration = factor(lure_consideration,
levels = c(0, 1),
labels = c("Lure Non-Considered", "Lure Considered")),
deliberation_function = factor(deliberation_function),
response              = factor(response),
subject_id            = factor(subject_id),
question              = factor(question)
) %>%
filter(lure_consideration %in% c("Lure Non-Considered", "Lure Considered"),
response %in% c("Correct", "Incorrect"))
# ----------------------------------------------------------------------------
# Model (as you did)
# ----------------------------------------------------------------------------
gam_model <- bam(
score ~ lure_consideration * response * deliberation_function +
s(normalized_position, by = interaction(lure_consideration, response, deliberation_function), k = 10) +
s(subject_id, bs = "re") +
s(question, bs = "re"),
data = chunks_long_lure,
method = "fREML"
)
summary(gam_model)
gam.check(gam_model)
appraise(gam_model)
# ----------------------------------------------------------------------------
# Generate Prediction Data
# ----------------------------------------------------------------------------
newdata <- expand.grid(
normalized_position = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long_lure$deliberation_function),
response = levels(chunks_long_lure$response),
lure_consideration = levels(chunks_long_lure$lure_consideration)
)
newdata$subject_id <- levels(chunks_long_lure$subject_id)[1]
newdata$question   <- levels(chunks_long_lure$question)[1]
predictions <- predict(
gam_model,
newdata = newdata,
se.fit = TRUE,
exclude = c("s(subject_id)", "s(question)")
)
newdata$pred <- predictions$fit
newdata$se   <- predictions$se.fit
# ----------------------------------------------------------------------------
# Compute Pairwise Differences: Lure vs No Lure
# ----------------------------------------------------------------------------
newdata$diff <- NA
newdata$pval <- NA
for(df in unique(newdata$deliberation_function)) {
for(resp in unique(newdata$response)) {
for(pos in unique(newdata$normalized_position)) {
tmp <- newdata %>%
filter(deliberation_function == df,
response == resp,
normalized_position == pos)
d  <- tmp$pred[tmp$lure_consideration == "Lure Considered"] -
tmp$pred[tmp$lure_consideration == "Lure Non-Considered"]
se <- sqrt(tmp$se[tmp$lure_consideration == "Lure Considered"]^2 +
tmp$se[tmp$lure_consideration == "Lure Non-Considered"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff[newdata$deliberation_function == df &
newdata$response == resp &
newdata$normalized_position == pos] <- d
newdata$pval[newdata$deliberation_function == df &
newdata$response == resp &
newdata$normalized_position == pos] <- pval
}
}
}
newdata <- newdata %>%
group_by(deliberation_function, response) %>%
mutate(pval_adj = p.adjust(pval, method = "fdr"),
significant = pval_adj < 0.05) %>%
ungroup()
newdata$significant <- newdata$pval_adj < 0.05
# ----------------------------------------------------------------------------
# Significant Regions
# ----------------------------------------------------------------------------
signif_regions <- newdata %>%
arrange(deliberation_function, response, normalized_position) %>%
group_by(deliberation_function, response) %>%
mutate(sig_grp = data.table::rleid(significant)) %>%
filter(significant) %>%
group_by(deliberation_function, response, sig_grp) %>%
summarise(xmin = min(normalized_position),
xmax = max(normalized_position)) %>%
ungroup()
# ----------------------------------------------------------------------------
# Plot
# ----------------------------------------------------------------------------
p_final <- ggplot() +
geom_line(data = newdata,
aes(x = normalized_position, y = pred,
color = lure_consideration),
size = 1) +
geom_ribbon(data = newdata,
aes(x = normalized_position, ymin = pred - 1.96 * se, ymax = pred + 1.96 * se,
fill = lure_consideration),
alpha = 0.2, color = NA) +
geom_rect(data = signif_regions,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "grey30", alpha = 0.1) +
facet_grid(response ~ deliberation_function) +
scale_color_manual(values = c("Lure Non-Considered" = "forestgreen",
"Lure Considered"   = "tomato3")) +
scale_fill_manual(values = c("Lure Non-Considered" = "forestgreen",
"Lure Considered"   = "tomato3")) +
theme_apa() +
labs(x = "Normalized Position in Verbalization",
y = "Predicted Score",
color = "Lure Consideration",
fill  = "Lure Consideration")
p_final
# ----------------------------------------------------------------------------
# Save
# ----------------------------------------------------------------------------
ggsave("./Output/gam_trajectory_lure_vs_no_lure_per_response_and_function.png",
p_final, dpi = 600, width = 12, height = 8)
# ----------------------------------------------------------------------------
# Recoding for clarity
# ----------------------------------------------------------------------------
chunks_long_fam <- chunks_long %>%
mutate(
familiar = factor(familiar, levels = c(0,1), labels = c("Unfamiliar", "Familiar")),
deliberation_function = factor(deliberation_function),
subject_id = factor(subject_id),
question   = factor(question)
) %>%
filter(familiar %in% c("Unfamiliar", "Familiar"))
# ----------------------------------------------------------------------------
# Model
# ----------------------------------------------------------------------------
gam_model_fam <- bam(
score ~ familiar * deliberation_function +
s(normalized_position, by = interaction(familiar, deliberation_function), k = 10) +
s(subject_id, bs = "re") +
s(question, bs = "re"),
data = chunks_long_fam,
method = "fREML"
)
summary(gam_model_fam)
gam.check(gam_model_fam)
appraise(gam_model_fam)
# ----------------------------------------------------------------------------
# Generate Prediction Data
# ----------------------------------------------------------------------------
newdata_fam <- expand.grid(
normalized_position = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long_fam$deliberation_function),
familiar = levels(chunks_long_fam$familiar)
)
newdata_fam$subject_id <- levels(chunks_long_fam$subject_id)[1]
newdata_fam$question   <- levels(chunks_long_fam$question)[1]
predictions_fam <- predict(
gam_model_fam,
newdata = newdata_fam,
se.fit = TRUE,
exclude = c("s(subject_id)", "s(question)")
)
newdata_fam$pred <- predictions_fam$fit
newdata_fam$se   <- predictions_fam$se.fit
# ----------------------------------------------------------------------------
# Compute Pairwise Differences: Familiar vs Unfamiliar
# ----------------------------------------------------------------------------
newdata_fam$diff <- NA
newdata_fam$pval <- NA
for(df in unique(newdata_fam$deliberation_function)) {
for(pos in unique(newdata_fam$normalized_position)) {
tmp <- newdata_fam %>%
filter(deliberation_function == df,
normalized_position == pos)
d  <- tmp$pred[tmp$familiar == "Familiar"] -
tmp$pred[tmp$familiar == "Unfamiliar"]
se <- sqrt(tmp$se[tmp$familiar == "Familiar"]^2 +
tmp$se[tmp$familiar == "Unfamiliar"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata_fam$diff[newdata_fam$deliberation_function == df &
newdata_fam$normalized_position == pos] <- d
newdata_fam$pval[newdata_fam$deliberation_function == df &
newdata_fam$normalized_position == pos] <- pval
}
}
newdata_fam <- newdata_fam %>%
group_by(deliberation_function) %>%
mutate(pval_adj = p.adjust(pval, method = "fdr"),
significant = pval_adj < 0.05) %>%
ungroup()
# ----------------------------------------------------------------------------
# Significant Regions
# ----------------------------------------------------------------------------
signif_regions_fam <- newdata_fam %>%
arrange(deliberation_function, normalized_position) %>%
group_by(deliberation_function) %>%
mutate(sig_grp = data.table::rleid(significant)) %>%
filter(significant) %>%
group_by(deliberation_function, sig_grp) %>%
summarise(xmin = min(normalized_position),
xmax = max(normalized_position)) %>%
ungroup()
# ----------------------------------------------------------------------------
# Plot
# ----------------------------------------------------------------------------
p_fam <- ggplot() +
geom_line(data = newdata_fam,
aes(x = normalized_position, y = pred,
color = familiar),
size = 1) +
geom_ribbon(data = newdata_fam,
aes(x = normalized_position, ymin = pred - 1.96 * se, ymax = pred + 1.96 * se,
fill = familiar),
alpha = 0.2, color = NA) +
geom_rect(data = signif_regions_fam,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "grey30", alpha = 0.1) +
facet_wrap(~ deliberation_function, scales = "free_y") +
scale_color_manual(values = c("Unfamiliar" = "grey30",
"Familiar" = "steelblue")) +
scale_fill_manual(values = c("Unfamiliar" = "grey30",
"Familiar" = "steelblue")) +
theme_apa() +
labs(x = "Normalized Position in Verbalization",
y = "Predicted Score",
color = "Familiarity",
fill  = "Familiarity")
p_fam
# ----------------------------------------------------------------------------
# Save
# ----------------------------------------------------------------------------
ggsave("./Output/gam_trajectory_familiar_vs_unfamiliar_per_function.png",
p_fam, dpi = 600, width = 12, height = 6)
