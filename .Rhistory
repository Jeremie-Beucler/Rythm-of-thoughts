)
summary(gam_model)
gam.check(gam_model)
# -------------------------------------------------------------
# Generate newdata grid
# -------------------------------------------------------------
newdata <- expand.grid(
norm_mid              = seq(0, 1, length.out = 15),
deliberation_function = levels(chunks_long$deliberation_function),
response              = levels(chunks_long$response)
)
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]
# Predict on response scale
pred_obj <- predict(
gam_model,
newdata  = newdata,
se.fit   = TRUE,
type     = "response",  # <-- keep predictions in raw score space
exclude  = c("s(subject_id)", "s(question)")
)
newdata <- newdata |>
mutate(
pred = pred_obj[[1]],
se   = pred_obj[[2]]
)
# -------------------------------------------------------------
# Compute Correct-vs-Incorrect differences & p-values (z-test)
# -------------------------------------------------------------
diff_df <- newdata |>
pivot_wider(names_from = response, values_from = c(pred, se)) |>
mutate(
diff    = pred_Correct - pred_Incorrect,
se_diff = sqrt(se_Correct^2 + se_Incorrect^2),
zval    = diff / se_diff,
pval    = 2 * (1 - pnorm(abs(zval)))
)
# FDR correction within each function
diff_df <- diff_df |>
group_by(deliberation_function) |>
mutate(pval_adj  = p.adjust(pval, method = "fdr"),
significant = pval_adj < .05) |>
ungroup()
library(data.table)   # for rleid()
sig_regions <- diff_df |>
arrange(deliberation_function, norm_mid) |>
group_by(deliberation_function) |>
mutate(grp = rleid(significant)) |>
filter(significant) |>
summarise(
xmin = min(norm_mid),
xmax = max(norm_mid),
.groups = "drop"
)
obs_means <- chunks_long |>
mutate(norm_mid_bin = cut(norm_mid,
breaks = seq(0, 1, length.out = 11),
labels = seq(.05, .95, length.out = 10))) |>
group_by(deliberation_function, response, norm_mid_bin) |>
summarise(
norm_mid   = first(as.numeric(as.character(norm_mid_bin))),
mean_score = mean(score) * 100,
.groups    = "drop"
)
library(ggplot2)
p_final <- ggplot() +
# GAM fits
geom_line(data = newdata,
aes(x = norm_mid, y = pred,
colour = response),
linewidth = 1) +
geom_ribbon(data = newdata,
aes(x = norm_mid,
ymin = pred - 1.96 * se,   # se on link → small; OK as visual guide
ymax = pred + 1.96 * se,
fill = response),
alpha = .2, colour = NA) +
# Significance rectangles
geom_rect(data = sig_regions,
aes(xmin = xmin, xmax = xmax,
ymin = -Inf, ymax = Inf),
fill = "grey30", alpha = .10) +
facet_wrap(~ deliberation_function, ncol = 2) +
scale_colour_manual(values = c(Correct = "forestgreen",
Incorrect = "tomato3")) +
scale_fill_manual(values = c(Correct = "forestgreen",
Incorrect = "tomato3")) +
theme_apa() +
labs(x = "Normalized Position in Verbalization",
y = "Predicted Score (0–100)",
colour = "Response",
fill   = "Response")
ggsave("./Output/gam_trajectory_per_response_and_function.png",
p_final, width = 12, height = 8, dpi = 600)
p_final   # view in R session
# compute mean accuracy per subject
# select subject_id, question, response
by_subject_accuracy <- chunks_long %>%
select(subject_id, question, response) %>%
distinct() %>%
group_by(subject_id) %>%
summarise(mean_accuracy = mean(response == "Correct", na.rm = TRUE)*100) %>%
ungroup()
# get median
median_accuracy <- median(by_subject_accuracy$mean_accuracy, na.rm = TRUE)
# plot the distrib with vertical dotted line for median
ggplot(by_subject_accuracy, aes(x = mean_accuracy)) +
geom_histogram(binwidth = 5, fill = "forestgreen", color = "black", alpha = 0.7) +
theme_apa() +
labs(x = "Mean Accuracy (%)",
y = "Count") +
scale_x_continuous(breaks = seq(0, 100, by = 10)) +
coord_cartesian(xlim = c(0, 100)) +
geom_vline(xintercept = median_accuracy, linetype = "dotted", color = "black")
# recode that in by_subject_accuracy (accuracy_high)
by_subject_accuracy <- by_subject_accuracy %>%
mutate(accuracy_high = ifelse(mean_accuracy >= median_accuracy, "High", "Low")) %>%
mutate(accuracy_high = factor(accuracy_high, levels = c("Low", "High")))
# add to chunks_long
chunks_long <- chunks_long %>%
left_join(by_subject_accuracy, by = "subject_id")
gam_model <- bam(
score ~ accuracy_high * response * deliberation_function +
s(norm_mid, by = interaction(accuracy_high, response, deliberation_function), k = 10) +
s(subject_id, bs = "re") +
s(question, bs = "re"),
data    = chunks_long,
method  = "fREML"
)
summary(gam_model)
gam.check(gam_model)
appraise(gam_model)
newdata <- expand.grid(
norm_mid              = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long$deliberation_function),
response              = levels(chunks_long$response),
accuracy_high         = levels(chunks_long$accuracy_high)
)
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]
predictions <- predict(
gam_model,
newdata = newdata,
se.fit  = TRUE,
type    = "response",
exclude = c("s(subject_id)", "s(question)")
)
newdata <- newdata %>%
mutate(
pred = predictions$fit,
se   = predictions$se.fit
)
newdata$diff <- NA
newdata$pval <- NA
for (f in unique(newdata$deliberation_function)) {
for (a in unique(newdata$accuracy_high)) {
for (pos in unique(newdata$norm_mid)) {
tmp <- newdata %>%
filter(deliberation_function == f,
accuracy_high == a,
norm_mid == pos)
d  <- tmp$pred[tmp$response == "Correct"] - tmp$pred[tmp$response == "Incorrect"]
se <- sqrt(tmp$se[tmp$response == "Correct"]^2 +
tmp$se[tmp$response == "Incorrect"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff[newdata$deliberation_function == f &
newdata$accuracy_high == a &
newdata$norm_mid == pos] <- d
newdata$pval[newdata$deliberation_function == f &
newdata$accuracy_high == a &
newdata$norm_mid == pos] <- pval
}
}
}
newdata <- newdata %>%
group_by(deliberation_function, accuracy_high) %>%
mutate(pval_adj = p.adjust(pval, method = "fdr"),
significant = pval_adj < 0.05) %>%
ungroup()
signif_regions <- newdata %>%
arrange(deliberation_function, accuracy_high, norm_mid) %>%
group_by(deliberation_function, accuracy_high) %>%
mutate(sig_grp = rleid(significant)) %>%
filter(significant) %>%
group_by(deliberation_function, accuracy_high, sig_grp) %>%
summarise(
xmin = min(norm_mid),
xmax = max(norm_mid),
.groups = "drop"
)
p_final <- ggplot() +
geom_line(data = newdata,
aes(x = norm_mid, y = pred, color = response),
linewidth = 1) +
geom_ribbon(data = newdata,
aes(x = norm_mid,
ymin = pred - 1.96 * se,
ymax = pred + 1.96 * se,
fill = response),
alpha = 0.2, color = NA) +
geom_rect(data = signif_regions,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "grey30", alpha = 0.1) +
facet_grid(accuracy_high ~ deliberation_function) +
scale_color_manual(values = c("Correct" = "forestgreen", "Incorrect" = "tomato3")) +
scale_fill_manual(values  = c("Correct" = "forestgreen", "Incorrect" = "tomato3")) +
theme_apa() +
labs(
x = "Normalized Position in Verbalization",
y = "Predicted Score",
color = "Response Type",
fill  = "Response Type"
)
ggsave("./Output/gam_trajectory_by_accuracy_and_function.png",
p_final, dpi = 600, width = 14, height = 9)
p_final
newdata$diff_highlow    <- NA
newdata$pval_highlow    <- NA
newdata$se_diff_highlow <- NA  # <- add this line
for (f in unique(newdata$deliberation_function)) {
for (r in unique(newdata$response)) {
for (pos in unique(newdata$norm_mid)) {
tmp <- newdata %>%
filter(deliberation_function == f,
response == r,
norm_mid == pos)
d  <- tmp$pred[tmp$accuracy_high == "High"] - tmp$pred[tmp$accuracy_high == "Low"]
se <- sqrt(tmp$se[tmp$accuracy_high == "High"]^2 +
tmp$se[tmp$accuracy_high == "Low"]^2)
zval <- d / se
pval <- 2 * (1 - pnorm(abs(zval)))
newdata$diff_highlow[newdata$deliberation_function == f &
newdata$response == r &
newdata$norm_mid == pos] <- d
newdata$se_diff_highlow[newdata$deliberation_function == f &
newdata$response == r &
newdata$norm_mid == pos] <- se
newdata$pval_highlow[newdata$deliberation_function == f &
newdata$response == r &
newdata$norm_mid == pos] <- pval
}
}
}
newdata <- newdata %>%
group_by(deliberation_function, response) %>%
mutate(pval_highlow_adj = p.adjust(pval_highlow, method = "fdr"),
significant_highlow = pval_highlow_adj < 0.05) %>%
ungroup()
signif_regions_highlow <- newdata %>%
arrange(deliberation_function, response, norm_mid) %>%
group_by(deliberation_function, response) %>%
mutate(sig_grp = rleid(significant_highlow)) %>%
filter(significant_highlow) %>%
group_by(deliberation_function, response, sig_grp) %>%
summarise(xmin = min(norm_mid),
xmax = max(norm_mid),
.groups = "drop")
p_diff <- ggplot() +
geom_hline(yintercept = 0, linetype = "dashed", color = "gray40") +
# Confidence ribbon
geom_ribbon(data = newdata %>% distinct(deliberation_function, response, norm_mid, .keep_all = TRUE),
aes(x = norm_mid,
ymin = diff_highlow - 1.96 * se_diff_highlow,
ymax = diff_highlow + 1.96 * se_diff_highlow),
fill = "black", alpha = 0.15) +
# Difference line
geom_line(data = newdata %>% distinct(deliberation_function, response, norm_mid, .keep_all = TRUE),
aes(x = norm_mid, y = diff_highlow),
color = "black", linewidth = 1) +
# Significance regions
geom_rect(data = signif_regions_highlow,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
fill = "steelblue", alpha = 0.2) +
facet_grid(response ~ deliberation_function) +
theme_apa() +
labs(
x = "Normalized Position in Verbalization",
y = "Difference (High - Low Accuracy)",
title = "Accuracy Group Differences per Response & Deliberation Function"
)
ggsave("./Output/gam_contrast_high_vs_low_accuracy.png",
p_diff, dpi = 600, width = 14, height = 9)
p_diff
ggsave("./Output/gam_contrast_high_vs_low_accuracy.png",
p_diff, dpi = 600, width = 14, height = 9)
p_diff
# ──────────────────────────────────────────────────────────────
# Full Pipeline: Uncertainty (n−1, n−2) → Deliberation Functions
# ──────────────────────────────────────────────────────────────
# Load libraries
library(mgcv)
library(emmeans)
library(knitr)
library(kableExtra)
library(broom)
library(stringr)
# Step 1: Add uncertainty and lag variables
chunks_scored <- chunks_scored %>%
mutate(response_uncertainty = 100 - response_confidence) %>%
arrange(subject_id, question, chunk_id) %>%
group_by(subject_id, question) %>%
mutate(
prev_uncertainty  = lag(response_uncertainty, 1),
prev2_uncertainty = lag(response_uncertainty, 2)
) %>%
ungroup()
# Step 2: Long format for 4 functions
chunks_long <- chunks_scored %>%
pivot_longer(
cols = c("response_control", "response_generation",
"response_justification", "response_regulation"),
names_to = "deliberation_function",
values_to = "score"
) %>%
mutate(
deliberation_function = recode_factor(
deliberation_function,
"response_control"       = "Control",
"response_generation"    = "Generation",
"response_justification" = "Justification",
"response_regulation"    = "Regulation"
),
chunk_id = as.numeric(chunk_id))
gam_linear <- bam(
score ~ deliberation_function * prev_uncertainty +
deliberation_function * prev2_uncertainty +
s(norm_mid, k = 6) +
s(subject_id, bs = "re") +
s(question,   bs = "re"),
data = chunks_long,
method = "fREML"
)
gam_smooth <- bam(
score ~ deliberation_function +
s(prev_uncertainty,  by = deliberation_function, k = 6) +
s(prev2_uncertainty, by = deliberation_function, k = 6) +
s(norm_mid, k = 6) +
s(subject_id, bs = "re") +
s(question,   bs = "re"),
data = chunks_long,
method = "fREML"
)
AIC(gam_linear, gam_smooth)
gam_smooth <- bam(
score ~ deliberation_function * prev_uncertainty +  # linear
s(prev_uncertainty, by = deliberation_function, k = 6) +  # smooth
deliberation_function * prev2_uncertainty +
s(prev2_uncertainty, by = deliberation_function, k = 6) +
s(norm_mid, k = 6) +
s(subject_id, bs = "re") +
s(question, bs = "re"),
data = chunks_long,
method = "fREML"
)
# Step 3B: Summary of smooth terms (edf, F, p)
gam_summary_tbl <- tidy(gam_smooth, parametric = FALSE) %>%
filter(str_detect(term, "prev_uncertainty|prev2_uncertainty")) %>%
mutate(
signif = case_when(
p.value < 0.001 ~ "***",
p.value < 0.01  ~ "**",
p.value < 0.05  ~ "*",
p.value < 0.1   ~ ".",
TRUE            ~ ""
)
) %>%
select(Smooth = term, EDF = edf, F = statistic, `p-value` = p.value, signif)
gam_summary_tbl %>%
kable(digits = 3, caption = "Smooth Terms from GAMM: Nonlinear Effects of Uncertainty") %>%
kable_styling(full_width = FALSE)
# ──────────────────────────────────────────────────────────────
#  Linear-slope part of the semi-parametric model  (emtrends)
# ──────────────────────────────────────────────────────────────
library(emmeans)
## ---------- 1. Average marginal slopes (n−1) ----------
em_n1 <- emtrends(gam_smooth,
specs = ~ deliberation_function,   # one slope per function
var   = "prev_uncertainty")        # linear term
n1_tbl <- summary(em_n1, infer = TRUE) |>
mutate(signif = case_when(
p.value < .001 ~ "***",
p.value < .01  ~ "**",
p.value < .05  ~ "*",
p.value < .10  ~ ".",
TRUE           ~ "")) |>
select(Function = deliberation_function,
Slope    = prev_uncertainty.trend,
SE       = SE,
t        = df,
`p-value`= p.value,
signif)
# Pairwise differences in those slopes
n1_pairs <- pairs(em_n1) |>
summary(infer = TRUE, adjust = "fdr")
## ---------- 2. Average marginal slopes (n−2) ----------
em_n2 <- emtrends(gam_smooth,
specs = ~ deliberation_function,
var   = "prev2_uncertainty")
n2_tbl <- summary(em_n2, infer = TRUE) |>
mutate(signif = case_when(
p.value < .001 ~ "***",
p.value < .01  ~ "**",
p.value < .05  ~ "*",
p.value < .10  ~ ".",
TRUE           ~ "")) |>
select(Function = deliberation_function,
Slope    = prev2_uncertainty.trend,
SE       = SE,
t        = df,
`p-value`= p.value,
signif)
n2_pairs <- pairs(em_n2) |>
summary(infer = TRUE, adjust = "fdr")
## ---------- 3. Nice tables ----------
library(knitr); library(kableExtra)
kable(n1_tbl, digits = 3,
caption = "Linear Slopes of Uncertainty at chunk n−1 (from `gam_smooth`)") |>
kable_styling(full_width = FALSE)
kable(n2_tbl, digits = 3,
caption = "Linear Slopes of Uncertainty at chunk n−2 (from `gam_smooth`)") |>
kable_styling(full_width = FALSE)
kable(n1_pairs, digits = 3,
caption = "Pairwise Differences of n−1 Slopes (FDR-corrected)") |>
kable_styling(full_width = FALSE)
kable(n2_pairs, digits = 3,
caption = "Pairwise Differences of n−2 Slopes (FDR-corrected)") |>
kable_styling(full_width = FALSE)
# Step 5A: Plot effect of prev_uncertainty (n−1)
one_id <- chunks_long$subject_id[!is.na(chunks_long$subject_id)][1]
one_q  <- chunks_long$question[!is.na(chunks_long$question)][1]
rng1 <- range(chunks_long$prev_uncertainty, na.rm = TRUE)
newd1 <- expand.grid(
prev_uncertainty       = seq(rng1[1], rng1[2], length.out = 100),
prev2_uncertainty      = median(chunks_long$prev2_uncertainty, na.rm = TRUE),
deliberation_function  = levels(chunks_long$deliberation_function),
norm_mid               = 0.5,
subject_id             = one_id,
question               = one_q
)
preds1 <- predict(gam_smooth, newdata = newd1, se.fit = TRUE)
newd1$fit <- preds1$fit
newd1$se  <- preds1$se.fit
newd1$upr <- newd1$fit + 1.96 * newd1$se
newd1$lwr <- newd1$fit - 1.96 * newd1$se
ggplot(newd1, aes(prev_uncertainty, fit,
colour = deliberation_function,
fill = deliberation_function)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .15, colour = NA) +
geom_line(size = 1) +
labs(x = "Uncertainty at chunk n−1",
y = "Predicted score at chunk n",
title = "Effect of Uncertainty at Chunk n−1",
colour = "Deliberation\nFunction",
fill   = "Deliberation\nFunction") +
theme_minimal(base_size = 13)
# Step 5B: Plot effect of prev2_uncertainty (n−2)
rng2 <- range(chunks_long$prev2_uncertainty, na.rm = TRUE)
newd2 <- expand.grid(
prev2_uncertainty      = seq(rng2[1], rng2[2], length.out = 100),
prev_uncertainty       = median(chunks_long$prev_uncertainty, na.rm = TRUE),
deliberation_function  = levels(chunks_long$deliberation_function),
norm_mid               = 0.5,
subject_id             = one_id,
question               = one_q
)
preds2 <- predict(gam_smooth, newdata = newd2, se.fit = TRUE)
newd2$fit <- preds2$fit
newd2$se  <- preds2$se.fit
newd2$upr <- newd2$fit + 1.96 * newd2$se
newd2$lwr <- newd2$fit - 1.96 * newd2$se
ggplot(newd2, aes(prev2_uncertainty, fit,
colour = deliberation_function,
fill = deliberation_function)) +
geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .15, colour = NA) +
geom_line(size = 1) +
labs(x = "Uncertainty at chunk n−2",
y = "Predicted score at chunk n",
title = "Effect of Uncertainty at Chunk n−2",
colour = "Deliberation\nFunction",
fill   = "Deliberation\nFunction") +
theme_minimal(base_size = 13)
# Step 6: Heatmap of n−1 × n−2 effects
grid <- expand.grid(
prev_uncertainty       = seq(rng1[1], rng1[2], length.out = 50),
prev2_uncertainty      = seq(rng2[1], rng2[2], length.out = 50),
deliberation_function  = levels(chunks_long$deliberation_function),
norm_mid               = 0.5,
subject_id             = one_id,
question               = one_q
)
preds_grid <- predict(gam_smooth, newdata = grid, se.fit = TRUE)
grid$fit <- preds_grid$fit
ggplot(grid, aes(x = prev_uncertainty, y = prev2_uncertainty, fill = fit)) +
geom_tile() +
scale_fill_gradient2(
low = "green3", mid = "white", high = "red3",
midpoint = mean(grid$fit, na.rm = TRUE),
name = "Predicted\nscore"
) +
facet_wrap(~ deliberation_function, ncol = 2) +
labs(
title = "Predicted Deliberation Score by Combined Uncertainty (n−1 × n−2)",
x = "Uncertainty at chunk n−1",
y = "Uncertainty at chunk n−2"
) +
theme_minimal(base_size = 13) +
theme(
strip.text = element_text(face = "bold"),
legend.title = element_text(face = "bold"),
panel.grid = element_blank()
)
