ggplot(chunks_long_question, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
stat_summary(fun = mean, geom = "col", alpha = 0.5) +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "black") +
labs(
x = "Deliberation Function",
y = "Average Score"
) +
theme_apa() +
theme(legend.position = "none")
ggsave("./Output/colplot_prevalence_functions_by_question.png", dpi = 600, width = 8, height = 5)
# now per accuracy
chunks_long_question <- chunks_long %>%
group_by(subject_id, question, deliberation_function, response) %>%
summarise(score = mean(score, na.rm = TRUE)) %>%
ungroup()
ggplot(chunks_long_question, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
geom_violin(trim = TRUE, alpha = 0.5) +
geom_jitter(width = 0.2, alpha = 0.3) +
stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "yellow") + # errorbars
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "yellow") +
facet_wrap(~response) +
labs(
x = "Deliberation Function",
y = "Score"
) +
theme_apa() +
theme(legend.position = "none")
ggsave("./Output/violin_plot_prevalence_functions_by_accuracy_question.png", dpi = 600, width = 8, height = 5)
ggplot(chunks_long_question, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
stat_summary(fun = mean, geom = "col", alpha = 0.5) +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "black") +
facet_wrap(~response) +
labs(
x = "Deliberation Function",
y = "Average Score"
) +
theme_apa() +
theme(legend.position = "none")
ggsave("./Output/colplot_prevalence_functions_by_accuracy_question.png", dpi = 600, width = 8, height = 5)
# ============================
# BINNING QUESTION DURATION
# ============================
# Build decile breaks
decile_breaks <- quantile(
chunks_long$question_duration_tot,
probs = seq(0, 1, 0.1),            # 0%,10%,…,100%
na.rm = TRUE
)
# Ensure cut() gets strictly increasing breaks
decile_breaks <- unique(decile_breaks)
# Bin question duration by deciles
chunks_long <- chunks_long %>%
mutate(
question_duration_tot_binned = cut(
question_duration_tot,
breaks = decile_breaks,
include.lowest = TRUE,
right = FALSE,
labels = NULL  # Use default labels like "(a,b]"
)
)
chunks_long <- chunks_long %>%
mutate(
duration_bin_label = as.character(question_duration_tot_binned),
question_duration_tot_binned = str_extract_all(duration_bin_label, "[0-9.]+") %>%
map(as.numeric) %>%
map_dbl(~ mean(.x))  # Compute midpoint
)
# ============================
# SUMMARY BY FUNCTION
# ============================
chunks_long_summary <- chunks_long %>%
group_by(question_duration_tot_binned, deliberation_function) %>%
summarise(
mean_score = mean(score, na.rm = TRUE),
se_score = sd(score, na.rm = TRUE) / sqrt(n()),
.groups = "drop"
)
# ============================
# PLOT: SCORE BY FUNCTION
# ============================
ggplot(chunks_long_summary, aes(x = question_duration_tot_binned, y = mean_score, color = deliberation_function, fill = deliberation_function)) +
geom_ribbon(aes(ymin = mean_score - se_score, ymax = mean_score + se_score), alpha = 0.15, color = NA) +
geom_line(size = 1) +
theme_apa() +
scale_color_manual(values = function_colors) +
scale_fill_manual(values = function_colors) +
labs(
x = "Total Question Duration (s)",
y = "Mean Score (± SE)",
color = "Deliberation Function",
fill = "Deliberation Function"
)
# ============================
# SUMMARY BY FUNCTION × ACCURACY
# ============================
chunks_long_summary <- chunks_long %>%
group_by(question_duration_tot_binned, deliberation_function, response) %>%
summarise(
mean_score = mean(score, na.rm = TRUE),
se_score = sd(score, na.rm = TRUE) / sqrt(n()),
.groups = "drop"
)
# ============================
# PLOT: SCORE BY FUNCTION × ACCURACY
# ============================
ggplot(chunks_long_summary, aes(x = question_duration_tot_binned, y = mean_score, color = deliberation_function, fill = deliberation_function)) +
geom_ribbon(aes(ymin = mean_score - se_score, ymax = mean_score + se_score), alpha = 0.15, color = NA) +
geom_line(size = 1) +
theme_apa() +
scale_color_manual(values = function_colors) +
scale_fill_manual(values = function_colors) +
labs(
x = "Total Question Duration (s)",
y = "Mean Score (± SE)",
color = "Deliberation Function",
fill = "Deliberation Function"
) +
facet_wrap(~response)
chunks_long <- chunks_long %>%
mutate(
deliberation_function = factor(deliberation_function),
response              = factor(response),
subject_id            = factor(subject_id),
question              = factor(question)
)
# ----------------------------------------------------------------------------
# Fit GAM Model without Response
# ----------------------------------------------------------------------------
gam_model <- bam(
score ~ deliberation_function +
s(norm_mid, by = deliberation_function, k = 10) +
s(subject_id, bs = "re") +
s(question,   bs = "re"),
data    = chunks_long,
method  = "fREML"
)
summary(gam_model)
gam.check(gam_model)
# ----------------------------------------------------------------------------
# Generate New Data for Predictions
# ----------------------------------------------------------------------------
newdata <- expand.grid(
norm_mid              = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long$deliberation_function)
)
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]
# Predict directly on the response scale (0–100)
predictions <- predict(
gam_model,
newdata  = newdata,
se.fit   = TRUE,
type     = "response",  # <- identity link
exclude  = c("s(subject_id)", "s(question)")
)
# Store predictions and CI
newdata <- newdata %>%
mutate(
pred     = predictions$fit,
lower_ci = pred - 1.96 * predictions$se.fit,
upper_ci = pred + 1.96 * predictions$se.fit
)
# ----------------------------------------------------------------------------
# Compute Observed Means for Overlay  (bin by identical grid as newdata)
# ----------------------------------------------------------------------------
observed_means <- chunks_long %>%
mutate(norm_mid_bin = cut(norm_mid,
breaks = seq(0, 1, length.out = 11),
labels = seq(0.05, 0.95, length.out = 10))) %>%
group_by(deliberation_function, norm_mid_bin) %>%
summarise(
norm_mid   = first(as.numeric(as.character(norm_mid_bin))),
mean_score = mean(score, na.rm = TRUE) * 100,
se_score   = sd(score,   na.rm = TRUE) / sqrt(n()) * 100,
.groups    = "drop"
)
# ----------------------------------------------------------------------------
# Plot: Trajectories per Deliberation Function
# ----------------------------------------------------------------------------
p_final <- ggplot() +
# Predicted GAM Fit Lines
geom_line(data = newdata,
aes(x = norm_mid, y = pred, color = deliberation_function), size = 1) +
# Confidence Intervals
geom_ribbon(data = newdata,
aes(x = norm_mid,
ymin = lower_ci,
ymax = upper_ci,
fill = deliberation_function),
alpha = 0.2, color = NA) +
theme_apa() +
labs(
x     = "Normalized Position in Verbalization",
y     = "Predicted Score (0–100)",
color = "Deliberation Function",
fill  = "Deliberation Function"
)
p_final
ggsave("./Output/gam_trajectory_functions_overall_trajectory.png",
p_final, dpi = 600, width = 12, height = 8)
# ----------------------------------------------------------------------------
# Generate New Data for Predictions
# ----------------------------------------------------------------------------
newdata <- expand.grid(
norm_mid              = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long$deliberation_function)
)
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]
# Predict directly on the response scale (0–100)
predictions <- predict(
gam_model,
newdata  = newdata,
se.fit   = TRUE,
type     = "response",  # <- identity link
exclude  = c("s(subject_id)", "s(question)")
)
# Store predictions and CI
newdata <- newdata %>%
mutate(
pred     = predictions$fit,
lower_ci = pred - 1.96 * predictions$se.fit,
upper_ci = pred + 1.96 * predictions$se.fit
)
# ----------------------------------------------------------------------------
# Compute Observed Means for Overlay  (bin by identical grid as newdata)
# ----------------------------------------------------------------------------
observed_means <- chunks_long %>%
mutate(norm_mid_bin = cut(norm_mid,
breaks = seq(0, 1, length.out = 11),
labels = seq(0.05, 0.95, length.out = 10))) %>%
group_by(deliberation_function, norm_mid_bin) %>%
summarise(
norm_mid   = first(as.numeric(as.character(norm_mid_bin))),
mean_score = mean(score, na.rm = TRUE) * 100,
se_score   = sd(score,   na.rm = TRUE) / sqrt(n()) * 100,
.groups    = "drop"
)
# ----------------------------------------------------------------------------
# Plot: Trajectories per Deliberation Function
# ----------------------------------------------------------------------------
p_final <- ggplot() +
# Predicted GAM Fit Lines
geom_line(data = newdata,
aes(x = norm_mid, y = pred, color = deliberation_function), size = 1) +
# Confidence Intervals
geom_ribbon(data = newdata,
aes(x = norm_mid,
ymin = lower_ci,
ymax = upper_ci,
fill = deliberation_function),
alpha = 0.2, color = NA) +
theme_apa() +
labs(
x     = "Normalized Position in Verbalization",
y     = "Predicted Score (0–100)",
color = "Deliberation Function",
fill  = "Deliberation Function"
)
p_final
ggsave("./Output/gam_trajectory_functions_overall_trajectory.png",
p_final, dpi = 600, width = 12, height = 8)
View(chunks_long)
# ----------------------------------------------------------------------------
# Generate New Data for Predictions
# ----------------------------------------------------------------------------
newdata <- expand.grid(
norm_mid              = seq(0, 1, length.out = 10),
deliberation_function = levels(chunks_long$deliberation_function)
)
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]
# Predict directly on the response scale (0–100)
predictions <- predict(
gam_model,
newdata  = newdata,
se.fit   = TRUE,
type     = "response",  # <- identity link
exclude  = c("s(subject_id)", "s(question)")
)
# Store predictions and CI
newdata <- newdata %>%
mutate(
pred     = predictions$fit,
lower_ci = pred - 1.96 * predictions$se.fit,
upper_ci = pred + 1.96 * predictions$se.fit
)
# ----------------------------------------------------------------------------
# Compute Observed Means for Overlay  (bin by identical grid as newdata)
# ----------------------------------------------------------------------------
observed_means <- chunks_long %>%
mutate(norm_mid_bin = cut(norm_mid,
breaks = seq(0, 1, length.out = 11),
labels = seq(0.05, 0.95, length.out = 10))) %>%
group_by(deliberation_function, norm_mid_bin) %>%
summarise(
norm_mid   = first(as.numeric(as.character(norm_mid_bin))),
mean_score = mean(score, na.rm = TRUE) * 100,
se_score   = sd(score,   na.rm = TRUE) / sqrt(n()) * 100,
.groups    = "drop"
)
# ----------------------------------------------------------------------------
# Plot: Trajectories per Deliberation Function
# ----------------------------------------------------------------------------
p_final <- ggplot() +
# Predicted GAM Fit Lines
geom_line(data = newdata,
aes(x = norm_mid, y = pred, color = deliberation_function), size = 1) +
# Confidence Intervals
geom_ribbon(data = newdata,
aes(x = norm_mid,
ymin = lower_ci,
ymax = upper_ci,
fill = deliberation_function),
alpha = 0.2, color = NA) +
theme_apa() +
labs(
x     = "Normalized Position in Verbalization",
y     = "Predicted Score (0–100)",
color = "Deliberation Function",
fill  = "Deliberation Function"
)
p_final
ggsave("./Output/gam_trajectory_functions_overall_trajectory.png",
p_final, dpi = 600, width = 12, height = 8)
# ----------------------------------------------------------------------------
# Step 1: Generate Predictions Per Deliberation Function
# ----------------------------------------------------------------------------
delib_functions <- c("Generation", "Justification", "Control", "Regulation")
newdata <- expand.grid(
norm_mid              = seq(0, 1, length.out = 15),
deliberation_function = delib_functions
)
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]
# Predict directly on response scale (no need to transform)
predictions <- predict(
gam_model,
newdata = newdata,
se.fit  = TRUE,
type    = "response",  # identity link
exclude = c("s(subject_id)", "s(question)")
)
# Add predictions and CIs to newdata
newdata <- newdata %>%
mutate(
pred     = predictions$fit,
se       = predictions$se.fit,
lower_ci = pred - 1.96 * se,
upper_ci = pred + 1.96 * se
)
# ----------------------------------------------------------------------------
# Step 2: Compute Manual Pairwise Differences
# ----------------------------------------------------------------------------
pairs <- combn(delib_functions, 2, simplify = FALSE)
diff_dfs <- list()
for(pair in pairs) {
func1 <- pair[1]
func2 <- pair[2]
df1 <- newdata %>% filter(deliberation_function == func1)
df2 <- newdata %>% filter(deliberation_function == func2)
diff_df <- df1 %>%
mutate(
deliberation_function_1 = func1,
deliberation_function_2 = func2,
diff      = pred - df2$pred,
se_diff   = sqrt(se^2 + df2$se^2),
zval      = diff / se_diff,
pval      = 2 * (1 - pnorm(abs(zval))),
lower_ci  = diff - 1.96 * se_diff,
upper_ci  = diff + 1.96 * se_diff
)
diff_dfs[[paste(func1, func2, sep = "_vs_")]] <- diff_df
}
diff_all <- bind_rows(diff_dfs)
# ----------------------------------------------------------------------------
# Step 3: Correct for Multiple Comparisons (FDR)
# ----------------------------------------------------------------------------
diff_all <- diff_all %>%
group_by(deliberation_function_1, deliberation_function_2) %>%
mutate(
pval_adj   = p.adjust(pval, method = "fdr"),
significant = pval_adj < 0.05
) %>%
ungroup()
# ----------------------------------------------------------------------------
# Step 4: Identify Significant Regions
# ----------------------------------------------------------------------------
library(data.table)  # for rleid
signif_regions_all <- diff_all %>%
arrange(deliberation_function_1, deliberation_function_2, norm_mid) %>%
group_by(deliberation_function_1, deliberation_function_2) %>%
mutate(sig_grp = rleid(significant)) %>%
filter(significant) %>%
group_by(deliberation_function_1, deliberation_function_2, sig_grp) %>%
summarise(
xmin = min(norm_mid),
xmax = max(norm_mid),
.groups = "drop"
)
# ----------------------------------------------------------------------------
# Step 5: Plot Difference Curves with CI and Significance Bands
# ----------------------------------------------------------------------------
library(ggplot2)
library(patchwork)
diff_plots <- list()
for(name in names(diff_dfs)) {
df <- diff_dfs[[name]]
sig_regions <- signif_regions_all %>%
filter(deliberation_function_1 == unique(df$deliberation_function_1),
deliberation_function_2 == unique(df$deliberation_function_2))
p <- ggplot(df, aes(x = norm_mid, y = diff)) +
geom_rect(data = sig_regions,
aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
inherit.aes = FALSE,
fill = "grey30", alpha = 0.1) +
geom_line(size = 1, color = "black") +
geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci),
fill = "grey70", alpha = 0.5) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(
title = paste0("Difference: ", unique(df$deliberation_function_1),
" - ", unique(df$deliberation_function_2)),
x = "Normalized Position in Verbalization",
y = "Difference in Score (0–100)"
) +
theme_apa()
diff_plots[[name]] <- p
}
p_diff_combined <- wrap_plots(diff_plots, ncol = 2)
p_diff_combined
# ----------------------------------------------------------------------------
# Step 6: Save Outputs
# ----------------------------------------------------------------------------
ggsave("./Output/gam_pairwise_functions_difference_trajectory.png",
p_diff_combined, width = 14, height = 10, dpi = 600)
# ----------------------------------------------------------------------------
# Fit GAM Model without Response
# ----------------------------------------------------------------------------
gam_model <- bam(
score ~ deliberation_function +
s(norm_mid, by = deliberation_function, k = 10) +
s(subject_id, bs = "re") +
s(question,   bs = "re"),
data    = chunks_long,
method  = "fREML"
)
derivs <- derivatives(gam_model, term = "s(norm_mid)", by = "deliberation_function")
derivs <- derivatives(gam_model, select = "s(norm_mid)", by = "deliberation_function")
summary(gam_model)
derivs <- derivatives(
gam_model,
select = "s(norm_mid)",
partial_match = TRUE
)
ggplot(derivs, aes(x = data, y = derivative, color = smooth)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper, fill = smooth), alpha = 0.2) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(x = "Normalized Time", y = "Rate of Change (Derivative)") +
theme_minimal()
View(derivs)
ggplot(derivs, aes(x = data, y = .derivative, color = smooth)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper, fill = smooth), alpha = 0.2) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(x = "Normalized Time", y = "Rate of Change (Derivative)") +
theme_minimal()
ggplot(derivs, aes(x = data, y = .derivative, color = smooth)) +
geom_line() +
geom_ribbon(aes(ymin = .lower_ci, ymax = .upper_ci, fill = smooth), alpha = 0.2) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(x = "Normalized Time", y = "Rate of Change (Derivative)") +
theme_minimal()
ggplot(derivs, aes(x = data, y = .derivative, color = .smooth)) +
geom_line() +
geom_ribbon(aes(ymin = .lower_ci, ymax = .upper_ci, fill = .smooth), alpha = 0.2) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(x = "Normalized Time", y = "Rate of Change (Derivative)") +
theme_minimal()
ggplot(derivs, aes(x = norm_mid, y = .derivative, color = .smooth)) +
geom_line() +
geom_ribbon(aes(ymin = .lower_ci, ymax = .upper_ci, fill = .smooth), alpha = 0.2) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(x = "Normalized Time", y = "Rate of Change (Derivative)") +
theme_minimal()
# exclude Repetition, Answer Selection, Confidence
chunks_long <- chunks_long %>%
filter(!deliberation_function %in% c("Repetition", "Answer Selection", "Confidence"))
# ----------------------------------------------------------------------------
# Fit GAM Model without Response
# ----------------------------------------------------------------------------
gam_model <- bam(
score ~ deliberation_function +
s(norm_mid, by = deliberation_function, k = 10) +
s(subject_id, bs = "re") +
s(question,   bs = "re"),
data    = chunks_long,
method  = "fREML"
)
derivs <- derivatives(
gam_model,
select = "s(norm_mid)",
partial_match = TRUE
)
ggplot(derivs, aes(x = norm_mid, y = .derivative, color = .smooth)) +
geom_line() +
geom_ribbon(aes(ymin = .lower_ci, ymax = .upper_ci, fill = .smooth), alpha = 0.2) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(x = "Normalized Time", y = "Rate of Change (Derivative)") +
theme_minimal()
