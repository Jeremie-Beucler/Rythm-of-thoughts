---
title: "Trajectory Analysis LLM"
author: "Jérémie Beucler"
date: "`r Sys.Date()`"
output: html_document
---

# Trajectory Analysis of Deliberation Functions

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# remove all objects
rm(list = ls())

# --------------------------------------------------------------------
# Libraries
# --------------------------------------------------------------------

library(zoo)
library(here)
library(ggplot2)
library(ggthemes)
library(data.table)
library(ggtext) # For markdown in titles
library(patchwork) # To combine plots
library(scales)    # Better axis formatting
library(viridis)   # Color palette
library(jtools)
library(mgcv)
library(gratia)  # for appraise(), difference_smooth(), etc.
library(itsadug) # for plot_diff(), concurrency checks, etc.
library(tidyverse)
library(ggcorrplot)  # For pretty correlation plots
library(Hmisc)

# --------------------------------------------------------------------
# Load Data
# --------------------------------------------------------------------
# Load scored chunks
chunks_scored <- read.csv("./Output/scored_chunks.csv")

data_long = read.csv("./Data/data_long.csv")


# --------------------------------------------------------------------
# Define Custom Colors for Functions
# --------------------------------------------------------------------
function_colors <- c(
  "Control" = "firebrick2",        # Red
  "Generation" = "royalblue1",     # Blue
  "Justification" = "gold2",  # Orange
  "Regulation" = "forestgreen",      # Green
  "Confidence" = "purple",          # Purple
  "Repetition" = "darkorange1",     # Dark Orange
  "Answer Selection" = "black"           # Black
)

# --------------------------------------------------------------------
# Merge additional variables
# --------------------------------------------------------------------
chunks_scored <- chunks_scored %>%
  rename(
    response_control = control_mean,
    response_generation = generation_mean,
    response_justification = justification_mean,
    response_regulation = regulation_mean,
    response_confidence = confidence_mean,
    response_repetition = repetition_mean,
    response_answer_selection = answer_selection_mean) %>% 
  left_join(data_long, by = c("subject_id", "question"))



# --------------------------------------------------------------------
# Filter to Keep Only Transcriptions with Reflect or Lure
# --------------------------------------------------------------------
chunks_scored <- chunks_scored %>%
  filter(response == "Reflect" | response == "Lure")

# filter out responses where max number of chunks is 1
chunks_scored <- chunks_scored %>%
  group_by(subject_id, question) %>%
  filter(max(chunk_id) > 1) %>%
  ungroup()

chunks_scored <- chunks_scored %>%
  mutate(response = ifelse(response == "Reflect", "Correct", "Incorrect"))
```

## Correlation between Deliberation Functions

```{r}
# --------------------------------------------------------------------
# Select Variables
# --------------------------------------------------------------------
cor_vars <- chunks_scored %>%
  select(response_control, response_generation, response_justification, response_regulation, response_confidence, response_repetition, response_answer_selection)

# --------------------------------------------------------------------
# Compute Correlation Matrix & p-values
# --------------------------------------------------------------------
cor_res <- Hmisc::rcorr(as.matrix(cor_vars), type = "pearson")

cor_matrix <- cor_res$r
p_matrix <- cor_res$P

# --------------------------------------------------------------------
# Plot Correlation Heatmap
# --------------------------------------------------------------------
ggcorrplot(cor_matrix, 
           type = "upper", 
           p.mat = p_matrix, 
           insig = "blank",        # Hide insignificant values
           lab = TRUE,             # Show correlation values
           lab_size = 4, 
           colors = c("darkblue", "white", "darkred"),
           outline.color = "grey50",
           legend.title = "r") +
  theme_apa() +
  theme(plot.title = element_text(face = "bold"),
        # rotate_x_text = 45, rotate_y_text = 45,
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(angle = 45, hjust = 1)) 

ggsave("./Output/deliberation_function_correlation_heatmap.png", dpi = 600, width = 8, height = 5)

```

## Validation with handscored data

```{r}
# --------------------------------------------------------------------
# Average Function Scores per Subject and Question
# --------------------------------------------------------------------
avg_scores <- chunks_scored %>%
  group_by(subject_id, question) %>%
  summarise(
    control = mean(response_control, na.rm = TRUE),
    generation = mean(response_generation, na.rm = TRUE),
    justification = mean(response_justification, na.rm = TRUE),
    regulation = mean(response_regulation, na.rm = TRUE),
    reconsidered_initial_resp = unique(reconsidered_initial_resp),
    verbalized_reasons = unique(verbalized_reasons),
    confidence = mean(response_confidence),
    repetition = mean(response_repetition), 
    answer_selection = mean(response_answer_selection)
  ) %>%
  ungroup()

# --------------------------------------------------------------------
# Filter to Binary Values Only
# --------------------------------------------------------------------
avg_scores_filtered <- avg_scores %>%
  filter(reconsidered_initial_resp %in% c(0, 1),
         verbalized_reasons %in% c(0, 1))

# --------------------------------------------------------------------
# Select Variables for Correlation
# --------------------------------------------------------------------
cor_vars_handscored <- avg_scores_filtered %>%
  select(control, generation, justification, regulation,
         reconsidered_initial_resp, verbalized_reasons, confidence, repetition, answer_selection)

# --------------------------------------------------------------------
# Compute Correlation Matrix with p-values
# --------------------------------------------------------------------
cor_res_handscored <- Hmisc::rcorr(as.matrix(cor_vars_handscored), type = "pearson")

cor_matrix_handscored <- cor_res_handscored$r
p_matrix_handscored <- cor_res_handscored$P

# --------------------------------------------------------------------
# Plot Correlation Heatmap
# --------------------------------------------------------------------
ggcorrplot(cor_matrix_handscored, 
           type = "upper", 
           p.mat = p_matrix_handscored, 
           insig = "blank",        
           lab = TRUE,             
           lab_size = 4, 
           colors = c("darkblue", "white", "darkred"),
           outline.color = "grey50",
           legend.title = "r") +
  theme_apa() +
  theme(plot.title = element_text(face = "bold"),
        # rotate_x_text = 45, rotate_y_text = 45,
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(angle = 45, hjust = 1)) 

ggsave("./Output/deliberation_function_handscored_variables_correlation_heatmap_handscored.png", dpi = 600, width = 8, height = 5)
```


## Chunks distributions

```{r}
# -------------------------------------------------------------
# Compute Normalized Time and Duration per Chunk
# -------------------------------------------------------------
chunks_scored <- chunks_scored %>%
  group_by(subject_id, question) %>%
  mutate(
    question_start = min(start_time, na.rm = TRUE),
    question_end = max(end_time, na.rm = TRUE),
    question_duration = question_end - question_start,
    norm_start = (start_time - question_start) / question_duration,
    norm_end = (end_time - question_start) / question_duration,
    norm_mid = ((start_time + end_time) / 2 - question_start) / question_duration,
    chunk_duration = end_time - start_time,
    question_duration_tot = max(end_time)
  ) %>%
  ungroup()


# --------------------------------------------------------------------
# Pivot Longer for Functions
# --------------------------------------------------------------------
chunks_long <- chunks_scored %>%
  pivot_longer(
    cols      = c(response_control, response_generation, response_justification,
                  response_regulation, response_confidence, response_repetition, 
                  response_answer_selection),
    names_to  = "deliberation_function",
    values_to = "score"
  ) %>%
  mutate(
    deliberation_function = recode(deliberation_function,
      response_control       = "Control",
      response_generation    = "Generation",
      response_justification = "Justification",
      response_regulation    = "Regulation",
      response_confidence    = "Confidence",
      response_repetition    = "Repetition",
      response_answer_selection = "Answer Selection"
      ),
    
    # factor conversions (unchanged)
    deliberation_function = factor(deliberation_function),
    response              = factor(response),
    subject_id            = factor(subject_id),
    question              = factor(question)
  )

```

```{r}
# --------------------------------------------------------------------
# Compute Number of Chunks per Question
# --------------------------------------------------------------------
n_chunks_df <- chunks_scored %>%
  group_by(subject_id, question, response) %>%
  summarise(n_chunks = max(chunk_id)) %>%
  ungroup()

# --------------------------------------------------------------------
# Summary Statistics (Overall)
# --------------------------------------------------------------------
print("Summary Statistics for Number of Chunks per Question (Overall):")
summary(n_chunks_df$n_chunks)

# --------------------------------------------------------------------
# Summary Statistics by Response
# --------------------------------------------------------------------
print("Summary Statistics for Number of Chunks per Question by Response:")

n_chunks_df %>%
  group_by(response) %>%
  summarise(
    count = n(),
    mean = mean(n_chunks),
    sd = sd(n_chunks),
    min = min(n_chunks),
    p25 = quantile(n_chunks, 0.25),
    median = median(n_chunks),
    p75 = quantile(n_chunks, 0.75),
    max = max(n_chunks)
  )

# --------------------------------------------------------------------
# Histogram of Number of Chunks (Overall)
# --------------------------------------------------------------------
ggplot(n_chunks_df, aes(x = n_chunks)) +
  geom_histogram(bins = 15, fill = "#1f77b4", color = "white", alpha = 0.8) +
  geom_density(aes(y = ..count..), color = "black", linewidth = 1) +
  labs(
    x = "Number of Chunks per Question",
    y = "Count"
  ) +
  theme_apa()

ggsave("./Output/histogram_n_chunks_overall.png", dpi = 600, width = 8, height = 5)

# --------------------------------------------------------------------
# Histogram of Number of Chunks (Grouped by Response)
# --------------------------------------------------------------------
ggplot(n_chunks_df, aes(x = n_chunks, fill = response)) +
  geom_histogram(bins = 15, alpha = 0.7, position = "identity", color = "white") +
  facet_wrap(~response, ncol = 2) +
  labs(
    x = "Number of Chunks per Question",
    y = "Count"
  ) +
  theme_apa()

ggsave("./Output/histogram_n_chunks_by_response.png", dpi = 600, width = 10, height = 6)

n_chunks_df_lure = chunks_scored %>%
  group_by(subject_id, question, lure_consideration) %>%
  summarise(n_chunks = max(chunk_id)) %>%
  ungroup()

# now by lure consideration
ggplot(n_chunks_df_lure, aes(x = n_chunks, fill = factor(lure_consideration))) +
  geom_histogram(bins = 15, alpha = 0.7, position = "identity", color = "white") +
  facet_wrap(~lure_consideration, ncol = 2) +
  labs(
    x = "Number of Chunks per Question",
    y = "Count"
  ) +
  theme_apa()

ggsave("./Output/histogram_n_chunks_by_lure_consideration.png", dpi = 600, width = 10, height = 6)

# now response and lure consideration
n_chunks_df_lure_resp = chunks_scored %>%
  group_by(subject_id, question, response, lure_consideration) %>%
  summarise(n_chunks = max(chunk_id)) %>%
  ungroup()

ggplot(n_chunks_df_lure_resp, aes(x = n_chunks, fill = factor(lure_consideration))) +
  geom_histogram(bins = 15, alpha = 0.7, position = "identity", color = "white") +
  facet_grid(
    rows = vars(response),
    cols = vars(lure_consideration),
    labeller = label_both
  ) +
  labs(
    x = "Number of Chunks per Question",
    y = "Count"
  ) +
  theme_apa()

ggsave("./Output/histogram_n_chunks_by_response_lure_consideration.png", dpi = 600, width = 10, height = 6)



# Define the function names once
functions <- c("Control", "Generation", "Justification", "Regulation")

chunks_dominant <- chunks_scored %>%
  rowwise() %>%
  mutate(
    # Store scores as a list (vector inside a list)
    scores = list(c_across(c(response_control, response_generation, response_justification, response_regulation))),
    
    max_score = max(unlist(scores)),
    n_max = sum(unlist(scores) == max_score),
    
    # Only assign dominant function if no tie
    dominant_function = ifelse(
      n_max == 1,
      functions[which.max(unlist(scores))],
      NA_character_
    )
  ) %>%
  ungroup() %>%
  filter(!is.na(dominant_function)) %>%
  mutate(
    word_count = str_count(chunk_text, "\\S+"),
    char_count = nchar(chunk_text)
  )

# Boxplot of chunk duration with mean
ggplot(chunks_dominant, aes(x = dominant_function, y = chunk_duration, fill = dominant_function)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 5, color = "yellow") +
  labs(
       x = "Dominant Function",
       y = "Average Chunk Duration (s)") +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/boxplot_chunk_duration.png", dpi = 600, width = 8, height = 5)

```


## Representative chunks

```{r}
###
# 1) Copy data & initialize columns
###

chunks_scores_loop <- chunks_scored

# Create distance columns
chunks_scores_loop$control_dist <- NA
chunks_scores_loop$generation_dist <- NA
chunks_scores_loop$justification_dist <- NA
chunks_scores_loop$regulation_dist <- NA

n_rows <- nrow(chunks_scores_loop)

###
# 2) Hardcore for-loop: compute distance from the (100, 0, 0, 0)-style ideal
#    for each function in every row
###

for (i in seq_len(n_rows)) {
  
  # Extract row as a plain R vector
  row <- chunks_scores_loop[i, ]
  
  # Scores for convenience
  sc <- row$response_control
  sg <- row$response_generation
  sj <- row$response_justification
  sr <- row$response_regulation
  
  # Control => Ideal is (100, 0, 0, 0)
  # We'll store the Euclidean distance (you can skip sqrt() if you prefer squared distance)
  chunks_scores_loop$control_dist[i] <-
    sqrt((sc - 100)^2 + (sg - 0)^2 + (sj - 0)^2 + (sr - 0)^2)
  
  # Generation => Ideal is (0, 100, 0, 0)
  chunks_scores_loop$generation_dist[i] <-
    sqrt((sc - 0)^2 + (sg - 100)^2 + (sj - 0)^2 + (sr - 0)^2)
  
  # Justification => Ideal is (0, 0, 100, 0)
  chunks_scores_loop$justification_dist[i] <-
    sqrt((sc - 0)^2 + (sg - 0)^2 + (sj - 100)^2 + (sr - 0)^2)
  
  # Regulation => Ideal is (0, 0, 0, 100)
  chunks_scores_loop$regulation_dist[i] <-
    sqrt((sc - 0)^2 + (sg - 0)^2 + (sj - 0)^2 + (sr - 100)^2)
}

###
# 3) Pick the top 3 "pure" chunks per function — i.e., the ones with the LOWEST distance
###

# Prepare container
representative_chunks <- tibble()

function_labels <- c("Control", "Generation", "Justification", "Regulation")
dist_cols       <- c("control_dist", "generation_dist", "justification_dist", "regulation_dist")

# For each function, find the 3 best matches
for (idx in seq_along(function_labels)) {
  
  f_label   <- function_labels[idx]  # "Control", ...
  dist_var  <- dist_cols[idx]       # "control_dist", ...
  
  # Subset, sort by that dist ascending
  best_rows <- chunks_scores_loop %>%
    arrange(.data[[dist_var]]) %>%
    slice_head(n = 5) %>%
    mutate(Max_representative = f_label)
  
  # Combine
  representative_chunks <- bind_rows(representative_chunks, best_rows)
}

###
# 4) Merge with question info & reorder columns
###

representative_chunks_annotated <- representative_chunks %>%
  select(
    Max_representative,
    chunk_text,
    question_text,
    correct_answer,
    lured_answer,
    # Original 4 function scores
    response_control,
    response_generation,
    response_justification,
    response_regulation,
    # Distances
    control_dist,
    generation_dist,
    justification_dist,
    regulation_dist
  ) %>% 
  rename(Function = Max_representative,
         Chunk = chunk_text,
         Question = question_text,
         Correct_answer = correct_answer,
         Lured_answer = lured_answer,
         Control = response_control,
         Generation = response_generation,
         Justification = response_justification,
         Regulation = response_regulation) %>%
  select(-c(control_dist, generation_dist, justification_dist, regulation_dist))

write.csv(representative_chunks_annotated, "./Output/representative_chunks.csv", row.names = FALSE)
```

## Overall Distribution of Deliberation Functions

### At the chunk level

```{r}

ggplot(chunks_long, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
  geom_violin(trim = TRUE, alpha = 0.5) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "yellow") + # errorbars
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "yellow") +
  labs(
    x = "Deliberation Function",
    y = "Score"
  ) +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/violin_plot_prevalence_functions.png", dpi = 600, width = 8, height = 5)

# colplot with se
ggplot(chunks_long, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
  stat_summary(fun = mean, geom = "col", alpha = 0.5) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "black") +
  labs(
    x = "Deliberation Function",
    y = "Average Score"
  ) +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/colplot_prevalence_functions.png", dpi = 600, width = 8, height = 5)

# now per accuracy
# violin
ggplot(chunks_long, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
  geom_violin(trim = TRUE, alpha = 0.5) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "yellow") + # errorbars
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "yellow") +
  facet_wrap(~response) +
  labs(
    x = "Deliberation Function",
    y = "Score"
  ) +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/violin_plot_prevalence_functions_by_accuracy.png", dpi = 600, width = 8, height = 5)

ggplot(chunks_long, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
  stat_summary(fun = mean, geom = "col", alpha = 0.5) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "black") +
  facet_wrap(~response) +
  labs(
    x = "Deliberation Function",
    y = "Average Score"
  ) +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/colplot_prevalence_functions_by_accuracy.png", dpi = 600, width = 8, height = 5)
```

### At the question level

```{r}
# first get mean by question
chunks_long_question <- chunks_long %>%
  group_by(subject_id, question, deliberation_function) %>%
  summarise(score = mean(score, na.rm = TRUE)) %>%
  ungroup()

# now plot
ggplot(chunks_long_question, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
  geom_violin(trim = TRUE, alpha = 0.5) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "yellow") + # errorbars
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "yellow") +
  labs(
    x = "Deliberation Function",
    y = "Score"
  ) +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/violin_plot_prevalence_functions_by_question.png", dpi = 600, width = 8, height = 5)

ggplot(chunks_long_question, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
  stat_summary(fun = mean, geom = "col", alpha = 0.5) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "black") +
  labs(
    x = "Deliberation Function",
    y = "Average Score"
  ) +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/colplot_prevalence_functions_by_question.png", dpi = 600, width = 8, height = 5)

# now per accuracy
chunks_long_question <- chunks_long %>%
  group_by(subject_id, question, deliberation_function, response) %>%
  summarise(score = mean(score, na.rm = TRUE)) %>%
  ungroup()

ggplot(chunks_long_question, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
  geom_violin(trim = TRUE, alpha = 0.5) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "yellow") + # errorbars
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "yellow") +
  facet_wrap(~response) +
  labs(
    x = "Deliberation Function",
    y = "Score"
  ) +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/violin_plot_prevalence_functions_by_accuracy_question.png", dpi = 600, width = 8, height = 5)

ggplot(chunks_long_question, aes(x = deliberation_function, y = score, fill = deliberation_function)) +
  stat_summary(fun = mean, geom = "col", alpha = 0.5) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.3, color = "black") +
  facet_wrap(~response) +
  labs(
    x = "Deliberation Function",
    y = "Average Score"
  ) +
  theme_apa() +
  theme(legend.position = "none")

ggsave("./Output/colplot_prevalence_functions_by_accuracy_question.png", dpi = 600, width = 8, height = 5)
```

## Deliberation Functions as a Function of Total Chunk Number

```{r}
# ============================
# BINNING QUESTION DURATION
# ============================

# Build decile breaks
decile_breaks <- quantile(
  chunks_long$question_duration_tot,
  probs = seq(0, 1, 0.1),            # 0%,10%,…,100%
  na.rm = TRUE
)

# Ensure cut() gets strictly increasing breaks
decile_breaks <- unique(decile_breaks)

# Bin question duration by deciles
chunks_long <- chunks_long %>% 
  mutate(
    question_duration_tot_binned = cut(
      question_duration_tot,
      breaks = decile_breaks,
      include.lowest = TRUE,
      right = FALSE,
      labels = NULL  # Use default labels like "(a,b]"
    )
  )

chunks_long <- chunks_long %>%
  mutate(
    duration_bin_label = as.character(question_duration_tot_binned),
    question_duration_tot_binned = str_extract_all(duration_bin_label, "[0-9.]+") %>% 
      map(as.numeric) %>%
      map_dbl(~ mean(.x))  # Compute midpoint
  )

# ============================
# SUMMARY BY FUNCTION
# ============================

chunks_long_summary <- chunks_long %>%
  group_by(question_duration_tot_binned, deliberation_function) %>%
  summarise(
    mean_score = mean(score, na.rm = TRUE),
    se_score = sd(score, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# ============================
# PLOT: SCORE BY FUNCTION
# ============================

ggplot(chunks_long_summary, aes(x = question_duration_tot_binned, y = mean_score, color = deliberation_function, fill = deliberation_function)) +
  geom_ribbon(aes(ymin = mean_score - se_score, ymax = mean_score + se_score), alpha = 0.15, color = NA) +
  geom_line(size = 1) +
  theme_apa() +
  scale_color_manual(values = function_colors) +
  scale_fill_manual(values = function_colors) +
  labs(
    x = "Total Question Duration (s)",
    y = "Mean Score (± SE)",
    color = "Deliberation Function",
    fill = "Deliberation Function"
  )

# ============================
# SUMMARY BY FUNCTION × ACCURACY
# ============================

chunks_long_summary <- chunks_long %>%
  group_by(question_duration_tot_binned, deliberation_function, response) %>%
  summarise(
    mean_score = mean(score, na.rm = TRUE),
    se_score = sd(score, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# ============================
# PLOT: SCORE BY FUNCTION × ACCURACY
# ============================

ggplot(chunks_long_summary, aes(x = question_duration_tot_binned, y = mean_score, color = deliberation_function, fill = deliberation_function)) +
  geom_ribbon(aes(ymin = mean_score - se_score, ymax = mean_score + se_score), alpha = 0.15, color = NA) +
  geom_line(size = 1) +
  theme_apa() +
  scale_color_manual(values = function_colors) +
  scale_fill_manual(values = function_colors) +
  labs(
    x = "Total Question Duration (s)",
    y = "Mean Score (± SE)",
    color = "Deliberation Function",
    fill = "Deliberation Function"
  ) +
  facet_wrap(~response)
```


## Trajectories

### GAMM Analyses

#### Overall

```{r}
chunks_long <- chunks_long %>%
  mutate(
    deliberation_function = factor(deliberation_function),
    response              = factor(response),
    subject_id            = factor(subject_id),
    question              = factor(question)
  )


# ----------------------------------------------------------------------------
# Fit GAM Model without Response
# ----------------------------------------------------------------------------
gam_model <- bam(
  score ~ deliberation_function +
    s(norm_mid, by = deliberation_function, k = 10) +
    s(subject_id, bs = "re") +
    s(question,   bs = "re"),
  data    = chunks_long,
  method  = "fREML"
)

summary(gam_model)
gam.check(gam_model)
```


```{r}
# ----------------------------------------------------------------------------
# Generate New Data for Predictions
# ----------------------------------------------------------------------------
newdata <- expand.grid(
  norm_mid              = seq(0, 1, length.out = 10),
  deliberation_function = levels(chunks_long$deliberation_function)
)
newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]

# Predict directly on the response scale (0–100)
predictions <- predict(
  gam_model,
  newdata  = newdata,
  se.fit   = TRUE,
  type     = "response",  # <- identity link
  exclude  = c("s(subject_id)", "s(question)")
)

# Store predictions and CI
newdata <- newdata %>%
  mutate(
    pred     = predictions$fit,
    lower_ci = pred - 1.96 * predictions$se.fit,
    upper_ci = pred + 1.96 * predictions$se.fit
  )

# ----------------------------------------------------------------------------
# Compute Observed Means for Overlay  (bin by identical grid as newdata)
# ----------------------------------------------------------------------------
observed_means <- chunks_long %>%
  mutate(norm_mid_bin = cut(norm_mid,
                            breaks = seq(0, 1, length.out = 11),
                            labels = seq(0.05, 0.95, length.out = 10))) %>%
  group_by(deliberation_function, norm_mid_bin) %>%
  summarise(
    norm_mid   = first(as.numeric(as.character(norm_mid_bin))),
    mean_score = mean(score, na.rm = TRUE) * 100,
    se_score   = sd(score,   na.rm = TRUE) / sqrt(n()) * 100,
    .groups    = "drop"
  )

# ----------------------------------------------------------------------------
# Plot: Trajectories per Deliberation Function
# ----------------------------------------------------------------------------
p_final <- ggplot() +
  # Predicted GAM Fit Lines
  geom_line(data = newdata,
            aes(x = norm_mid, y = pred, color = deliberation_function), size = 1) +

  # Confidence Intervals
  geom_ribbon(data = newdata,
              aes(x = norm_mid,
                  ymin = lower_ci,
                  ymax = upper_ci,
                  fill = deliberation_function),
              alpha = 0.2, color = NA) +

  facet_wrap(~ deliberation_function, ncol = 2, scale = "free") +
  theme_apa() +
  labs(
    x     = "Normalized Position in Verbalization",
    y     = "Predicted Score (0–100)",
    color = "Deliberation Function",
    fill  = "Deliberation Function"
  )

p_final

ggsave("./Output/gam_trajectory_functions_overall_trajectory.png",
       p_final, dpi = 600, width = 12, height = 8)
```





```{r}
# ----------------------------------------------------------------------------
# Step 1: Generate Predictions Per Deliberation Function
# ----------------------------------------------------------------------------

delib_functions <- c("Generation", "Justification", "Control", "Regulation")

newdata <- expand.grid(
  norm_mid              = seq(0, 1, length.out = 15),
  deliberation_function = delib_functions
)

newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]

# Predict directly on response scale (no need to transform)
predictions <- predict(
  gam_model,
  newdata = newdata,
  se.fit  = TRUE,
  type    = "response",  # identity link
  exclude = c("s(subject_id)", "s(question)")
)

# Add predictions and CIs to newdata
newdata <- newdata %>%
  mutate(
    pred     = predictions$fit,
    se       = predictions$se.fit,
  lower_ci = pred - 1.96 * se,
  upper_ci = pred + 1.96 * se
)

# ----------------------------------------------------------------------------
# Step 2: Compute Manual Pairwise Differences
# ----------------------------------------------------------------------------

pairs <- combn(delib_functions, 2, simplify = FALSE)
diff_dfs <- list()

for(pair in pairs) {
  
  func1 <- pair[1]
  func2 <- pair[2]
  
  df1 <- newdata %>% filter(deliberation_function == func1)
  df2 <- newdata %>% filter(deliberation_function == func2)
  
  diff_df <- df1 %>%
    mutate(
      deliberation_function_1 = func1,
      deliberation_function_2 = func2,
      diff      = pred - df2$pred,
      se_diff   = sqrt(se^2 + df2$se^2),
      zval      = diff / se_diff,
      pval      = 2 * (1 - pnorm(abs(zval))),
      lower_ci  = diff - 1.96 * se_diff,
      upper_ci  = diff + 1.96 * se_diff
    )
  
  diff_dfs[[paste(func1, func2, sep = "_vs_")]] <- diff_df
}

diff_all <- bind_rows(diff_dfs)

# ----------------------------------------------------------------------------
# Step 3: Correct for Multiple Comparisons (FDR)
# ----------------------------------------------------------------------------

diff_all <- diff_all %>%
  group_by(deliberation_function_1, deliberation_function_2) %>%
  mutate(
    pval_adj   = p.adjust(pval, method = "fdr"),
    significant = pval_adj < 0.05
  ) %>%
  ungroup()

# ----------------------------------------------------------------------------
# Step 4: Identify Significant Regions
# ----------------------------------------------------------------------------

library(data.table)  # for rleid

signif_regions_all <- diff_all %>%
  arrange(deliberation_function_1, deliberation_function_2, norm_mid) %>%
  group_by(deliberation_function_1, deliberation_function_2) %>%
  mutate(sig_grp = rleid(significant)) %>%
  filter(significant) %>%
  group_by(deliberation_function_1, deliberation_function_2, sig_grp) %>%
  summarise(
    xmin = min(norm_mid),
    xmax = max(norm_mid),
    .groups = "drop"
  )

# ----------------------------------------------------------------------------
# Step 5: Plot Difference Curves with CI and Significance Bands
# ----------------------------------------------------------------------------

library(ggplot2)
library(patchwork)

diff_plots <- list()

for(name in names(diff_dfs)) {
  
  df <- diff_dfs[[name]]
  
  sig_regions <- signif_regions_all %>%
    filter(deliberation_function_1 == unique(df$deliberation_function_1),
           deliberation_function_2 == unique(df$deliberation_function_2))
  
  p <- ggplot(df, aes(x = norm_mid, y = diff)) +
    geom_rect(data = sig_regions,
              aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
              inherit.aes = FALSE,
              fill = "grey30", alpha = 0.1) +
    geom_line(size = 1, color = "black") +
    geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci),
                fill = "grey70", alpha = 0.5) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(
      title = paste0("Difference: ", unique(df$deliberation_function_1), 
                     " - ", unique(df$deliberation_function_2)),
      x = "Normalized Position in Verbalization",
      y = "Difference in Score (0–100)"
    ) +
    theme_apa()

    
    
  diff_plots[[name]] <- p
}

p_diff_combined <- wrap_plots(diff_plots, ncol = 2)

p_diff_combined

# ----------------------------------------------------------------------------
# Step 6: Save Outputs
# ----------------------------------------------------------------------------

ggsave("./Output/gam_pairwise_functions_difference_trajectory.png",
       p_diff_combined, width = 14, height = 10, dpi = 600)
```

```{r}
library(patchwork)
library(viridisLite)
library(glue)
library(grid)   # unit()

# ------------------------------------------------------------------
# Build all pairwise 2-function trajectory plots
# ------------------------------------------------------------------
delib_functions  <- unique(newdata$deliberation_function)
function_pairs   <- combn(delib_functions, 2, simplify = FALSE)

trajectory_plots <- list()

for (pair in function_pairs) {

  f1 <- as.character(pair[1])   # <- convert to plain strings
  f2 <- as.character(pair[2]) 

  # -------- reshape so every norm_mid row has BOTH columns ----------
  pair_data <- newdata %>%
    filter(deliberation_function %in% c(f1, f2)) %>%
    select(norm_mid, deliberation_function, pred) %>%
    pivot_wider(names_from  = deliberation_function,
                values_from = pred) %>%
    drop_na(all_of(c(f1, f2))) %>%          # keep rows with both preds
    arrange(norm_mid)

  # -------- 2-D trajectory plot -------------------------------------
  p <- ggplot(pair_data,
              aes(x = .data[[f1]],
                  y = .data[[f2]],
                  colour = norm_mid,
                  group = 1)) +             # one continuous path
    geom_path(arrow = arrow(type  = "open",
                            length = unit(0.15, "inches")),
              linewidth = 1.2) +
    scale_colour_viridis_c(name = "Normalized\nTime (0–1)") +
    theme_minimal(base_size = 14) +
    labs(title = glue("Trajectory: {f1} → {f2}"),
         x = glue("Predicted {f1} (0–100)"),
         y = glue("Predicted {f2} (0–100)"))  +
    geom_abline(slope = 1, intercept = 0, linetype = "dotted", color = "black") +
    coord_fixed(ratio = 1) +
    theme_apa() +
    xlim(0, 30) +
    ylim(0, 30) 


  trajectory_plots[[paste(f1, f2, sep = "_vs_")]] <- p
}

# ------------------------------------------------------------------
# Optional combined grid
# ------------------------------------------------------------------
library(ggpubr)

p_grid <- ggarrange(
  plotlist = trajectory_plots,
  ncol     = 2,
  nrow     = 3
)

ggsave(
  filename = "./Output/gam_2d_trajectories_all_pairs.png",
  plot     = p_grid,
  width    = 20, height = 20, dpi = 600
)

p_grid   # shows in viewer
```




#### Per Accuracy

```{r}
# remove confidence and repetition for now
chunks_long <- chunks_long %>%
  filter(!deliberation_function %in% c("Confidence", "Repetition", "Answer Selection")) %>% 
  mutate(
    deliberation_function = factor(deliberation_function))

# -------------------------------------------------------------------------
# Fit GAM (Beta family)  –– Response × Function with time-varying smooth
# -------------------------------------------------------------------------
gam_model <- bam(
  score ~ response * deliberation_function +
    s(norm_mid,
      by = interaction(response, deliberation_function),
      k  = 10) +
    s(subject_id, bs = "re") +
    s(question,   bs = "re"),
  data    = chunks_long,
  method  = "fREML"
)

summary(gam_model)
gam.check(gam_model)
```


```{r}
# -------------------------------------------------------------
# Generate newdata grid
# -------------------------------------------------------------
newdata <- expand.grid(
  norm_mid              = seq(0, 1, length.out = 15),
  deliberation_function = levels(chunks_long$deliberation_function),
  response              = levels(chunks_long$response)
)

newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]

# Predict on response scale
pred_obj <- predict(
  gam_model,
  newdata  = newdata,
  se.fit   = TRUE,
  type     = "response",  # <-- keep predictions in raw score space
  exclude  = c("s(subject_id)", "s(question)")
)

newdata <- newdata |>
  mutate(
    pred = pred_obj[[1]],
    se   = pred_obj[[2]]
  )

# -------------------------------------------------------------
# Compute Correct-vs-Incorrect differences & p-values (z-test)
# -------------------------------------------------------------
diff_df <- newdata |>
  pivot_wider(names_from = response, values_from = c(pred, se)) |>
  mutate(
    diff    = pred_Correct - pred_Incorrect,
    se_diff = sqrt(se_Correct^2 + se_Incorrect^2),
    zval    = diff / se_diff,
    pval    = 2 * (1 - pnorm(abs(zval)))
  )

# FDR correction within each function
diff_df <- diff_df |>
  group_by(deliberation_function) |>
  mutate(pval_adj  = p.adjust(pval, method = "fdr"),
         significant = pval_adj < .05) |>
  ungroup()

library(data.table)   # for rleid()
sig_regions <- diff_df |>
  arrange(deliberation_function, norm_mid) |>
  group_by(deliberation_function) |>
  mutate(grp = rleid(significant)) |>
  filter(significant) |>
  summarise(
    xmin = min(norm_mid),
    xmax = max(norm_mid),
    .groups = "drop"
  )

obs_means <- chunks_long |>
  mutate(norm_mid_bin = cut(norm_mid,
                            breaks = seq(0, 1, length.out = 11),
                            labels = seq(.05, .95, length.out = 10))) |>
  group_by(deliberation_function, response, norm_mid_bin) |>
  summarise(
    norm_mid   = first(as.numeric(as.character(norm_mid_bin))),
    mean_score = mean(score) * 100,
    .groups    = "drop"
  )

library(ggplot2)

p_final <- ggplot() +
  # GAM fits
  geom_line(data = newdata,
            aes(x = norm_mid, y = pred,
                colour = response),
            linewidth = 1) +
  geom_ribbon(data = newdata,
              aes(x = norm_mid,
                  ymin = pred - 1.96 * se,   # se on link → small; OK as visual guide
                  ymax = pred + 1.96 * se,
                  fill = response),
              alpha = .2, colour = NA) +
  # Significance rectangles
  geom_rect(data = sig_regions,
            aes(xmin = xmin, xmax = xmax,
                ymin = -Inf, ymax = Inf),
            fill = "grey30", alpha = .10) +
  facet_wrap(~ deliberation_function, ncol = 2) +
  scale_colour_manual(values = c(Correct = "forestgreen",
                                 Incorrect = "tomato3")) +
  scale_fill_manual(values = c(Correct = "forestgreen",
                               Incorrect = "tomato3")) +
  theme_apa() +
  labs(x = "Normalized Position in Verbalization",
       y = "Predicted Score (0–100)",
       colour = "Response",
       fill   = "Response")

ggsave("./Output/gam_trajectory_per_response_and_function.png",
       p_final, width = 12, height = 8, dpi = 600)

p_final   # view in R session


```

## Interindividual Differences

```{r}
# compute mean accuracy per subject
# select subject_id, question, response
by_subject_accuracy <- chunks_long %>%
  select(subject_id, question, response) %>%
  distinct() %>%
  group_by(subject_id) %>%
  summarise(mean_accuracy = mean(response == "Correct", na.rm = TRUE)*100) %>%
  ungroup()

# get median
median_accuracy <- median(by_subject_accuracy$mean_accuracy, na.rm = TRUE)


# plot the distrib with vertical dotted line for median
ggplot(by_subject_accuracy, aes(x = mean_accuracy)) +
  geom_histogram(binwidth = 5, fill = "forestgreen", color = "black", alpha = 0.7) +
  theme_apa() +
  labs(x = "Mean Accuracy (%)",
       y = "Count") +
  scale_x_continuous(breaks = seq(0, 100, by = 10)) +
  coord_cartesian(xlim = c(0, 100)) + 
  geom_vline(xintercept = median_accuracy, linetype = "dotted", color = "black")


# recode that in by_subject_accuracy (accuracy_high)
by_subject_accuracy <- by_subject_accuracy %>%
  mutate(accuracy_high = ifelse(mean_accuracy >= median_accuracy, "High", "Low")) %>%
  mutate(accuracy_high = factor(accuracy_high, levels = c("Low", "High")))

# add to chunks_long
chunks_long <- chunks_long %>%
  left_join(by_subject_accuracy, by = "subject_id")
```

### Overall

Interaction with response.

```{r}
gam_model <- bam(
  score ~ accuracy_high * response * deliberation_function +
    s(norm_mid, by = interaction(accuracy_high, response, deliberation_function), k = 10) +
    s(subject_id, bs = "re") +
    s(question, bs = "re"),
  data    = chunks_long,
  method  = "fREML"
)

summary(gam_model)
gam.check(gam_model)
appraise(gam_model)
```

```{r}
newdata <- expand.grid(
  norm_mid              = seq(0, 1, length.out = 10),
  deliberation_function = levels(chunks_long$deliberation_function),
  response              = levels(chunks_long$response),
  accuracy_high         = levels(chunks_long$accuracy_high)
)

newdata$subject_id <- levels(chunks_long$subject_id)[1]
newdata$question   <- levels(chunks_long$question)[1]

predictions <- predict(
  gam_model,
  newdata = newdata,
  se.fit  = TRUE,
  type    = "response",
  exclude = c("s(subject_id)", "s(question)")
)

newdata <- newdata %>%
  mutate(
    pred = predictions$fit,
    se   = predictions$se.fit
  )
```

```{r}
newdata$diff <- NA
newdata$pval <- NA

for (f in unique(newdata$deliberation_function)) {
  for (a in unique(newdata$accuracy_high)) {
    for (pos in unique(newdata$norm_mid)) {
      
      tmp <- newdata %>%
        filter(deliberation_function == f,
               accuracy_high == a,
               norm_mid == pos)
      
      d  <- tmp$pred[tmp$response == "Correct"] - tmp$pred[tmp$response == "Incorrect"]
      se <- sqrt(tmp$se[tmp$response == "Correct"]^2 +
                 tmp$se[tmp$response == "Incorrect"]^2)
      
      zval <- d / se
      pval <- 2 * (1 - pnorm(abs(zval)))
      
      newdata$diff[newdata$deliberation_function == f &
                   newdata$accuracy_high == a &
                   newdata$norm_mid == pos] <- d
      
      newdata$pval[newdata$deliberation_function == f &
                   newdata$accuracy_high == a &
                   newdata$norm_mid == pos] <- pval
    }
  }
}

newdata <- newdata %>%
  group_by(deliberation_function, accuracy_high) %>%
  mutate(pval_adj = p.adjust(pval, method = "fdr"),
         significant = pval_adj < 0.05) %>%
  ungroup()

signif_regions <- newdata %>%
  arrange(deliberation_function, accuracy_high, norm_mid) %>%
  group_by(deliberation_function, accuracy_high) %>%
  mutate(sig_grp = rleid(significant)) %>%
  filter(significant) %>%
  group_by(deliberation_function, accuracy_high, sig_grp) %>%
  summarise(
    xmin = min(norm_mid),
    xmax = max(norm_mid),
    .groups = "drop"
  )

p_final <- ggplot() +
  geom_line(data = newdata,
            aes(x = norm_mid, y = pred, color = response),
            linewidth = 1) +
  geom_ribbon(data = newdata,
              aes(x = norm_mid,
                  ymin = pred - 1.96 * se,
                  ymax = pred + 1.96 * se,
                  fill = response),
              alpha = 0.2, color = NA) +
  geom_rect(data = signif_regions,
            aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
            fill = "grey30", alpha = 0.1) +
  facet_grid(accuracy_high ~ deliberation_function) +
  scale_color_manual(values = c("Correct" = "forestgreen", "Incorrect" = "tomato3")) +
  scale_fill_manual(values  = c("Correct" = "forestgreen", "Incorrect" = "tomato3")) +
  theme_apa() +
  labs(
    x = "Normalized Position in Verbalization",
    y = "Predicted Score",
    color = "Response Type",
    fill  = "Response Type"
  )

ggsave("./Output/gam_trajectory_by_accuracy_and_function.png",
       p_final, dpi = 600, width = 14, height = 9)

p_final

```


```{r}
newdata$diff_highlow    <- NA
newdata$pval_highlow    <- NA
newdata$se_diff_highlow <- NA  # <- add this line

for (f in unique(newdata$deliberation_function)) {
  for (r in unique(newdata$response)) {
    for (pos in unique(newdata$norm_mid)) {
      
      tmp <- newdata %>%
        filter(deliberation_function == f,
               response == r,
               norm_mid == pos)
      
      d  <- tmp$pred[tmp$accuracy_high == "High"] - tmp$pred[tmp$accuracy_high == "Low"]
      se <- sqrt(tmp$se[tmp$accuracy_high == "High"]^2 +
                 tmp$se[tmp$accuracy_high == "Low"]^2)
      
      zval <- d / se
      pval <- 2 * (1 - pnorm(abs(zval)))
      
      newdata$diff_highlow[newdata$deliberation_function == f &
                           newdata$response == r &
                           newdata$norm_mid == pos] <- d
      
      newdata$se_diff_highlow[newdata$deliberation_function == f &
                              newdata$response == r &
                              newdata$norm_mid == pos] <- se
      
      newdata$pval_highlow[newdata$deliberation_function == f &
                           newdata$response == r &
                           newdata$norm_mid == pos] <- pval
    }
  }
}

newdata <- newdata %>%
  group_by(deliberation_function, response) %>%
  mutate(pval_highlow_adj = p.adjust(pval_highlow, method = "fdr"),
         significant_highlow = pval_highlow_adj < 0.05) %>%
  ungroup()

signif_regions_highlow <- newdata %>%
  arrange(deliberation_function, response, norm_mid) %>%
  group_by(deliberation_function, response) %>%
  mutate(sig_grp = rleid(significant_highlow)) %>%
  filter(significant_highlow) %>%
  group_by(deliberation_function, response, sig_grp) %>%
  summarise(xmin = min(norm_mid),
            xmax = max(norm_mid),
            .groups = "drop")

p_diff <- ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray40") +

  # Confidence ribbon
  geom_ribbon(data = newdata %>% distinct(deliberation_function, response, norm_mid, .keep_all = TRUE),
              aes(x = norm_mid,
                  ymin = diff_highlow - 1.96 * se_diff_highlow,
                  ymax = diff_highlow + 1.96 * se_diff_highlow),
              fill = "black", alpha = 0.15) +

  # Difference line
  geom_line(data = newdata %>% distinct(deliberation_function, response, norm_mid, .keep_all = TRUE),
            aes(x = norm_mid, y = diff_highlow),
            color = "black", linewidth = 1) +

  # Significance regions
  geom_rect(data = signif_regions_highlow,
            aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
            fill = "steelblue", alpha = 0.2) +

  facet_grid(response ~ deliberation_function) +
  theme_apa() +
  labs(
    x = "Normalized Position in Verbalization",
    y = "Difference (High - Low Accuracy)",
    title = "Accuracy Group Differences per Response & Deliberation Function"
  )

ggsave("./Output/gam_contrast_high_vs_low_accuracy.png",
       p_diff, dpi = 600, width = 14, height = 9)

p_diff

ggsave("./Output/gam_contrast_high_vs_low_accuracy.png",
       p_diff, dpi = 600, width = 14, height = 9)

p_diff
```


## Confidence deliberation link

```{r}
# ──────────────────────────────────────────────────────────────
# Full Pipeline: Uncertainty (n−1, n−2) → Deliberation Functions
# ──────────────────────────────────────────────────────────────

# Load libraries
library(mgcv)
library(emmeans)
library(knitr)
library(kableExtra)
library(broom)
library(stringr)

# Step 1: Add uncertainty and lag variables
chunks_scored <- chunks_scored %>%
  mutate(response_uncertainty = 100 - response_confidence) %>%
  arrange(subject_id, question, chunk_id) %>%
  group_by(subject_id, question) %>%
  mutate(
    prev_uncertainty  = lag(response_uncertainty, 1),
    prev2_uncertainty = lag(response_uncertainty, 2)
  ) %>%
  ungroup()

# Step 2: Long format for 4 functions
chunks_long <- chunks_scored %>%
  pivot_longer(
    cols = c("response_control", "response_generation",
             "response_justification", "response_regulation"),
    names_to = "deliberation_function",
    values_to = "score"
  ) %>%
  mutate(
    deliberation_function = recode_factor(
      deliberation_function,
      "response_control"       = "Control",
      "response_generation"    = "Generation",
      "response_justification" = "Justification",
      "response_regulation"    = "Regulation"
    ),
    chunk_id = as.numeric(chunk_id))
```



```{r}
gam_linear <- bam(
  score ~ deliberation_function * prev_uncertainty +
          deliberation_function * prev2_uncertainty +
          s(norm_mid, k = 6) +
          s(subject_id, bs = "re") +
          s(question,   bs = "re"),
  data = chunks_long,
  method = "fREML"
)

gam_smooth <- bam(
  score ~ deliberation_function +
          s(prev_uncertainty,  by = deliberation_function, k = 6) +
          s(prev2_uncertainty, by = deliberation_function, k = 6) +
          s(norm_mid, k = 6) +
          s(subject_id, bs = "re") +
          s(question,   bs = "re"),
  data = chunks_long,
  method = "fREML"
)

AIC(gam_linear, gam_smooth)

gam_smooth <- bam(
  score ~ deliberation_function * prev_uncertainty +  # linear
          s(prev_uncertainty, by = deliberation_function, k = 6) +  # smooth
          deliberation_function * prev2_uncertainty +
          s(prev2_uncertainty, by = deliberation_function, k = 6) +
          s(norm_mid, k = 6) +
          s(subject_id, bs = "re") +
          s(question, bs = "re"),
  data = chunks_long,
  method = "fREML"
)

```




```{r}
# Step 3B: Summary of smooth terms (edf, F, p)
gam_summary_tbl <- tidy(gam_smooth, parametric = FALSE) %>%
  filter(str_detect(term, "prev_uncertainty|prev2_uncertainty")) %>%
  mutate(
    signif = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      p.value < 0.1   ~ ".",
      TRUE            ~ ""
    )
  ) %>%
  select(Smooth = term, EDF = edf, F = statistic, `p-value` = p.value, signif)

gam_summary_tbl %>%
  kable(digits = 3, caption = "Smooth Terms from GAMM: Nonlinear Effects of Uncertainty") %>%
  kable_styling(full_width = FALSE)

# ──────────────────────────────────────────────────────────────
#  Linear-slope part of the semi-parametric model  (emtrends)
# ──────────────────────────────────────────────────────────────

library(emmeans)

## ---------- 1. Average marginal slopes (n−1) ----------
em_n1 <- emtrends(gam_smooth,
                  specs = ~ deliberation_function,   # one slope per function
                  var   = "prev_uncertainty")        # linear term

n1_tbl <- summary(em_n1, infer = TRUE) |>
  mutate(signif = case_when(
            p.value < .001 ~ "***",
            p.value < .01  ~ "**",
            p.value < .05  ~ "*",
            p.value < .10  ~ ".",
            TRUE           ~ "")) |>
  select(Function = deliberation_function,
         Slope    = prev_uncertainty.trend,
         SE       = SE,
         t        = df,
         `p-value`= p.value,
         signif)

# Pairwise differences in those slopes
n1_pairs <- pairs(em_n1) |>
  summary(infer = TRUE, adjust = "fdr")

## ---------- 2. Average marginal slopes (n−2) ----------
em_n2 <- emtrends(gam_smooth,
                  specs = ~ deliberation_function,
                  var   = "prev2_uncertainty")

n2_tbl <- summary(em_n2, infer = TRUE) |>
  mutate(signif = case_when(
            p.value < .001 ~ "***",
            p.value < .01  ~ "**",
            p.value < .05  ~ "*",
            p.value < .10  ~ ".",
            TRUE           ~ "")) |>
  select(Function = deliberation_function,
         Slope    = prev2_uncertainty.trend,
         SE       = SE,
         t        = df,
         `p-value`= p.value,
         signif)

n2_pairs <- pairs(em_n2) |>
  summary(infer = TRUE, adjust = "fdr")

## ---------- 3. Nice tables ----------
library(knitr); library(kableExtra)

kable(n1_tbl, digits = 3,
      caption = "Linear Slopes of Uncertainty at chunk n−1 (from `gam_smooth`)") |>
  kable_styling(full_width = FALSE)

kable(n2_tbl, digits = 3,
      caption = "Linear Slopes of Uncertainty at chunk n−2 (from `gam_smooth`)") |>
  kable_styling(full_width = FALSE)

kable(n1_pairs, digits = 3,
      caption = "Pairwise Differences of n−1 Slopes (FDR-corrected)") |>
  kable_styling(full_width = FALSE)

kable(n2_pairs, digits = 3,
      caption = "Pairwise Differences of n−2 Slopes (FDR-corrected)") |>
  kable_styling(full_width = FALSE)













# Step 5A: Plot effect of prev_uncertainty (n−1)
one_id <- chunks_long$subject_id[!is.na(chunks_long$subject_id)][1]
one_q  <- chunks_long$question[!is.na(chunks_long$question)][1]

rng1 <- range(chunks_long$prev_uncertainty, na.rm = TRUE)
newd1 <- expand.grid(
  prev_uncertainty       = seq(rng1[1], rng1[2], length.out = 100),
  prev2_uncertainty      = median(chunks_long$prev2_uncertainty, na.rm = TRUE),
  deliberation_function  = levels(chunks_long$deliberation_function),
  norm_mid               = 0.5,
  subject_id             = one_id,
  question               = one_q
)
preds1 <- predict(gam_smooth, newdata = newd1, se.fit = TRUE)
newd1$fit <- preds1$fit
newd1$se  <- preds1$se.fit
newd1$upr <- newd1$fit + 1.96 * newd1$se
newd1$lwr <- newd1$fit - 1.96 * newd1$se

ggplot(newd1, aes(prev_uncertainty, fit,
                  colour = deliberation_function,
                  fill = deliberation_function)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .15, colour = NA) +
  geom_line(size = 1) +
  labs(x = "Uncertainty at chunk n−1",
       y = "Predicted score at chunk n",
       title = "Effect of Uncertainty at Chunk n−1",
       colour = "Deliberation\nFunction",
       fill   = "Deliberation\nFunction") +
  theme_minimal(base_size = 13)

# Step 5B: Plot effect of prev2_uncertainty (n−2)
rng2 <- range(chunks_long$prev2_uncertainty, na.rm = TRUE)
newd2 <- expand.grid(
  prev2_uncertainty      = seq(rng2[1], rng2[2], length.out = 100),
  prev_uncertainty       = median(chunks_long$prev_uncertainty, na.rm = TRUE),
  deliberation_function  = levels(chunks_long$deliberation_function),
  norm_mid               = 0.5,
  subject_id             = one_id,
  question               = one_q
)
preds2 <- predict(gam_smooth, newdata = newd2, se.fit = TRUE)
newd2$fit <- preds2$fit
newd2$se  <- preds2$se.fit
newd2$upr <- newd2$fit + 1.96 * newd2$se
newd2$lwr <- newd2$fit - 1.96 * newd2$se

ggplot(newd2, aes(prev2_uncertainty, fit,
                  colour = deliberation_function,
                  fill = deliberation_function)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = .15, colour = NA) +
  geom_line(size = 1) +
  labs(x = "Uncertainty at chunk n−2",
       y = "Predicted score at chunk n",
       title = "Effect of Uncertainty at Chunk n−2",
       colour = "Deliberation\nFunction",
       fill   = "Deliberation\nFunction") +
  theme_minimal(base_size = 13)

# Step 6: Heatmap of n−1 × n−2 effects
grid <- expand.grid(
  prev_uncertainty       = seq(rng1[1], rng1[2], length.out = 50),
  prev2_uncertainty      = seq(rng2[1], rng2[2], length.out = 50),
  deliberation_function  = levels(chunks_long$deliberation_function),
  norm_mid               = 0.5,
  subject_id             = one_id,
  question               = one_q
)
preds_grid <- predict(gam_smooth, newdata = grid, se.fit = TRUE)
grid$fit <- preds_grid$fit

ggplot(grid, aes(x = prev_uncertainty, y = prev2_uncertainty, fill = fit)) +
  geom_tile() +
  scale_fill_gradient2(
    low = "green3", mid = "white", high = "red3",
    midpoint = mean(grid$fit, na.rm = TRUE),
    name = "Predicted\nscore"
  ) +
  facet_wrap(~ deliberation_function, ncol = 2) +
  labs(
    title = "Predicted Deliberation Score by Combined Uncertainty (n−1 × n−2)",
    x = "Uncertainty at chunk n−1",
    y = "Uncertainty at chunk n−2"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    strip.text = element_text(face = "bold"),
    legend.title = element_text(face = "bold"),
    panel.grid = element_blank()
  )

```

## Complementary Analyses

### Trajectories per Accuracy and Lure Consideration

```{r}
# ----------------------------------------------------------------------------
# Recoding for clarity
# ----------------------------------------------------------------------------
chunks_long_lure <- chunks_long %>%
  mutate(
    lure_consideration = factor(lure_consideration, 
                                levels = c(0, 1), 
                                labels = c("Lure Non-Considered", "Lure Considered")),
    deliberation_function = factor(deliberation_function),
    response              = factor(response),
    subject_id            = factor(subject_id),
    question              = factor(question)
  ) %>% 
  filter(lure_consideration %in% c("Lure Non-Considered", "Lure Considered"),
         response %in% c("Correct", "Incorrect"))

# ----------------------------------------------------------------------------
# Model (as you did)
# ----------------------------------------------------------------------------
gam_model <- bam(
  score ~ lure_consideration * response * deliberation_function + 
    s(norm_mid, by = interaction(lure_consideration, response, deliberation_function), k = 10) +
    s(subject_id, bs = "re") +
    s(question, bs = "re"),
  data = chunks_long_lure,
  method = "fREML"
)

summary(gam_model)
gam.check(gam_model)
appraise(gam_model)

# ----------------------------------------------------------------------------
# Generate Prediction Data
# ----------------------------------------------------------------------------
newdata <- expand.grid(
  norm_mid = seq(0, 1, length.out = 10),
  deliberation_function = levels(chunks_long_lure$deliberation_function),
  response = levels(chunks_long_lure$response),
  lure_consideration = levels(chunks_long_lure$lure_consideration)
)

newdata$subject_id <- levels(chunks_long_lure$subject_id)[1]
newdata$question   <- levels(chunks_long_lure$question)[1]

predictions <- predict(
  gam_model,
  newdata = newdata,
  se.fit = TRUE,
  exclude = c("s(subject_id)", "s(question)")
)

newdata$pred <- predictions$fit
newdata$se   <- predictions$se.fit

# ----------------------------------------------------------------------------
# Compute Pairwise Differences: Lure vs No Lure
# ----------------------------------------------------------------------------
newdata$diff <- NA
newdata$pval <- NA

for(df in unique(newdata$deliberation_function)) {
  for(resp in unique(newdata$response)) {
    for(pos in unique(newdata$normalized_position)) {
      
      tmp <- newdata %>%
        filter(deliberation_function == df,
               response == resp,
               normalized_position == pos)
      
      d  <- tmp$pred[tmp$lure_consideration == "Lure Considered"] - 
            tmp$pred[tmp$lure_consideration == "Lure Non-Considered"]
      
      se <- sqrt(tmp$se[tmp$lure_consideration == "Lure Considered"]^2 +
                 tmp$se[tmp$lure_consideration == "Lure Non-Considered"]^2)
      
      zval <- d / se
      pval <- 2 * (1 - pnorm(abs(zval)))
      
      newdata$diff[newdata$deliberation_function == df & 
                   newdata$response == resp &
                   newdata$normalized_position == pos] <- d
      
      newdata$pval[newdata$deliberation_function == df & 
                   newdata$response == resp &
                   newdata$normalized_position == pos] <- pval
    }
  }
}

newdata <- newdata %>%
  group_by(deliberation_function, response) %>%
  mutate(pval_adj = p.adjust(pval, method = "fdr"),
         significant = pval_adj < 0.05) %>%
  ungroup()

newdata$significant <- newdata$pval_adj < 0.05

# ----------------------------------------------------------------------------
# Significant Regions
# ----------------------------------------------------------------------------
signif_regions <- newdata %>%
  arrange(deliberation_function, response, norm_mid) %>%
  group_by(deliberation_function, response) %>%
  mutate(sig_grp = data.table::rleid(significant)) %>%
  filter(significant) %>%
  group_by(deliberation_function, response, sig_grp) %>%
  summarise(xmin = min(norm_mid),
            xmax = max(norm_mid)) %>%
  ungroup()

# ----------------------------------------------------------------------------
# Plot
# ----------------------------------------------------------------------------
p_final <- ggplot() +
  
  geom_line(data = newdata,
            aes(x = norm_mid, y = pred, 
                color = lure_consideration),
            size = 1) +
  
  geom_ribbon(data = newdata,
              aes(x = norm_mid, ymin = pred - 1.96 * se, ymax = pred + 1.96 * se,
                  fill = lure_consideration),
              alpha = 0.2, color = NA) +
  
  geom_rect(data = signif_regions,
            aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
            fill = "grey30", alpha = 0.1) +
  
  facet_grid(response ~ deliberation_function) +
  
scale_color_manual(values = c("Lure Non-Considered" = "forestgreen",
                                "Lure Considered"   = "tomato3")) +
  scale_fill_manual(values = c("Lure Non-Considered" = "forestgreen",
                               "Lure Considered"   = "tomato3")) +
  
  theme_apa() +
  
  labs(x = "Normalized Position in Verbalization",
       y = "Predicted Score",
       color = "Lure Consideration",
       fill  = "Lure Consideration")

p_final

# ----------------------------------------------------------------------------
# Save
# ----------------------------------------------------------------------------
ggsave("./Output/gam_trajectory_lure_vs_no_lure_per_response_and_function.png",
       p_final, dpi = 600, width = 12, height = 8)

```

### Trajectories per Familiarity

```{r}
# ----------------------------------------------------------------------------
# Recoding for clarity
# ----------------------------------------------------------------------------
chunks_long_fam <- chunks_long %>%
  mutate(
    familiar = factor(familiar, levels = c(0,1), labels = c("Unfamiliar", "Familiar")),
    deliberation_function = factor(deliberation_function),
    subject_id = factor(subject_id),
    question   = factor(question)
  ) %>%
  filter(familiar %in% c("Unfamiliar", "Familiar"))

# ----------------------------------------------------------------------------
# Model
# ----------------------------------------------------------------------------
gam_model_fam <- bam(
  score ~ familiar * deliberation_function + 
    s(norm_mid, by = interaction(familiar, deliberation_function), k = 10) +
    s(subject_id, bs = "re") +
    s(question, bs = "re"),
  data = chunks_long_fam,
  method = "fREML"
)

summary(gam_model_fam)
gam.check(gam_model_fam)
appraise(gam_model_fam)

# ----------------------------------------------------------------------------
# Generate Prediction Data
# ----------------------------------------------------------------------------
newdata_fam <- expand.grid(
  norm_mid = seq(0, 1, length.out = 10),
  deliberation_function = levels(chunks_long_fam$deliberation_function),
  familiar = levels(chunks_long_fam$familiar)
)

newdata_fam$subject_id <- levels(chunks_long_fam$subject_id)[1]
newdata_fam$question   <- levels(chunks_long_fam$question)[1]

predictions_fam <- predict(
  gam_model_fam,
  newdata = newdata_fam,
  se.fit = TRUE,
  exclude = c("s(subject_id)", "s(question)")
)

newdata_fam$pred <- predictions_fam$fit
newdata_fam$se   <- predictions_fam$se.fit

# ----------------------------------------------------------------------------
# Compute Pairwise Differences: Familiar vs Unfamiliar
# ----------------------------------------------------------------------------
newdata_fam$diff <- NA
newdata_fam$pval <- NA

for(df in unique(newdata_fam$deliberation_function)) {
  for(pos in unique(newdata_fam$norm_mid)) {
    
    tmp <- newdata_fam %>%
      filter(deliberation_function == df,
             norm_mid == pos)
    
    d  <- tmp$pred[tmp$familiar == "Familiar"] - 
          tmp$pred[tmp$familiar == "Unfamiliar"]
    
    se <- sqrt(tmp$se[tmp$familiar == "Familiar"]^2 +
               tmp$se[tmp$familiar == "Unfamiliar"]^2)
    
    zval <- d / se
    pval <- 2 * (1 - pnorm(abs(zval)))
    
    newdata_fam$diff[newdata_fam$deliberation_function == df & 
                     newdata_fam$norm_mid == pos] <- d
    
    newdata_fam$pval[newdata_fam$deliberation_function == df & 
                     newdata_fam$norm_mid == pos] <- pval
  }
}

newdata_fam <- newdata_fam %>%
  group_by(deliberation_function) %>%
  mutate(pval_adj = p.adjust(pval, method = "fdr"),
         significant = pval_adj < 0.05) %>%
  ungroup()

# ----------------------------------------------------------------------------
# Significant Regions
# ----------------------------------------------------------------------------
signif_regions_fam <- newdata_fam %>%
  arrange(deliberation_function, norm_mid) %>%
  group_by(deliberation_function) %>%
  mutate(sig_grp = data.table::rleid(significant)) %>%
  filter(significant) %>%
  group_by(deliberation_function, sig_grp) %>%
  summarise(xmin = min(norm_mid),
            xmax = max(norm_mid)) %>%
  ungroup()

# ----------------------------------------------------------------------------
# Plot
# ----------------------------------------------------------------------------
p_fam <- ggplot() +
  
  geom_line(data = newdata_fam,
            aes(x = norm_mid, y = pred, 
                color = familiar),
            size = 1) +
  
  geom_ribbon(data = newdata_fam,
              aes(x = norm_mid, ymin = pred - 1.96 * se, ymax = pred + 1.96 * se,
                  fill = familiar),
              alpha = 0.2, color = NA) +
  
  geom_rect(data = signif_regions_fam,
            aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
            fill = "grey30", alpha = 0.1) +
  
  facet_wrap(~ deliberation_function, scales = "free_y") +
  
scale_color_manual(values = c("Unfamiliar" = "grey30",
                               "Familiar" = "steelblue")) +
scale_fill_manual(values = c("Unfamiliar" = "grey30",
                              "Familiar" = "steelblue")) +
  
  theme_apa() +
  
  labs(x = "Normalized Position in Verbalization",
       y = "Predicted Score",
       color = "Familiarity",
       fill  = "Familiarity")

p_fam

# ----------------------------------------------------------------------------
# Save
# ----------------------------------------------------------------------------
ggsave("./Output/gam_trajectory_familiar_vs_unfamiliar_per_function.png",
       p_fam, dpi = 600, width = 12, height = 6)
```
