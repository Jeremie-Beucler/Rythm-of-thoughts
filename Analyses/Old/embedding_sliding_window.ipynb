{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe0c384-02a1-4940-94af-19322070d2db",
   "metadata": {},
   "source": [
    "# Embedding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "646b0396-bff6-4c82-86de-fc88bc118274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 1. Import necessary libraries\n",
    "# --------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "800e4860-161e-46e1-a49d-537b6ee0cd72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 2. Load data\n",
    "# --------------------------------------------------------------------\n",
    "data_long = pd.read_csv('../Data/data_long.csv', encoding='utf-8-sig')\n",
    "prototypes_df = pd.read_csv('../Data/prototypes_llama3.3.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bf76e808-6500-48c8-8828-f86ba4fac455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription length statistics:\n",
      "count    1020.000000\n",
      "mean       41.275490\n",
      "std        37.342953\n",
      "min         1.000000\n",
      "25%        18.000000\n",
      "50%        33.000000\n",
      "75%        55.000000\n",
      "max       368.000000\n",
      "Name: transcription_length, dtype: float64\n",
      "\n",
      "Transcription length quantiles:\n",
      "0.25     18.00\n",
      "0.50     33.00\n",
      "0.75     55.00\n",
      "0.90     81.00\n",
      "0.95    105.00\n",
      "0.99    185.86\n",
      "Name: transcription_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 3. Compute statistics on transcription_new\n",
    "# --------------------------------------------------------------------\n",
    "# Compute length of each transcription (in words)\n",
    "data_long['transcription_length'] = data_long['transcription_new'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "print(\"Transcription length statistics:\")\n",
    "print(data_long['transcription_length'].describe())\n",
    "print(\"\\nTranscription length quantiles:\")\n",
    "print(data_long['transcription_length'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "787549b5-8e8a-47a7-a2c7-99191410da32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.4.0.dev0, however, your version is 2.4.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 4. Load embedding model\n",
    "# --------------------------------------------------------------------\n",
    "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "da059852-607a-4297-9d2c-82fccc1c37ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototype embeddings computed and normalized (no merging).\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 5. Compute Prototype Embeddings (No Merging)\n",
    "# --------------------------------------------------------------------\n",
    "prototype_embeddings = {}\n",
    "\n",
    "for question_id in prototypes_df['question'].unique():\n",
    "    subset = prototypes_df[prototypes_df['question'] == question_id]\n",
    "\n",
    "    for func in subset['function'].unique():\n",
    "\n",
    "        sentences = subset[subset['function'] == func]['prototypes'].values[0].split(\"\\n\")\n",
    "        sentences = [s.split(\". \", 1)[1] for s in sentences if \". \" in s]\n",
    "        sentences = [\"clustering: \" + s for s in sentences]\n",
    "\n",
    "        embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "        # Store mean embedding directly without merging\n",
    "        prototype_embeddings[(question_id, func)] = F.normalize(embeddings.mean(dim=0), p=2, dim=0)\n",
    "\n",
    "print(\"Prototype embeddings computed and normalized (no merging).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "778f3e1c-e0ab-483d-91d1-7051701b8e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding sliding windows: 100%|██████████| 1020/1020 [04:25<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliding window embedding analysis complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# Sliding Window Embedding of Transcription_new\n",
    "# --------------------------------------------------------------------\n",
    "window_size = 5  # number of words\n",
    "stride = 3\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in tqdm(data_long.iterrows(), total=len(data_long), desc=\"Embedding sliding windows\"):\n",
    "    transcription = str(row['transcription_new'])\n",
    "    words = transcription.split()\n",
    "\n",
    "    if len(words) <= window_size:\n",
    "        windows = [\" \".join(words)]\n",
    "        starts = [0]\n",
    "    else:\n",
    "        windows = [\" \".join(words[start:start + window_size]) for start in range(0, len(words) - window_size + 1, stride)]\n",
    "        starts = list(range(0, len(words) - window_size + 1, stride))\n",
    "\n",
    "    for start, window_text in zip(starts, windows):\n",
    "        window_emb = model.encode(\"clustering: \" + window_text, convert_to_tensor=True)\n",
    "\n",
    "        for func in ['control', 'generation', 'justification', 'regulation']:\n",
    "            proto_emb = prototype_embeddings.get((row['question'], func))\n",
    "            if proto_emb is not None:\n",
    "                similarity = util.cos_sim(window_emb, proto_emb).item()\n",
    "\n",
    "                # Create result dict from row\n",
    "                result = row.to_dict()\n",
    "\n",
    "                # Add sliding window info\n",
    "                result.update({\n",
    "                    'start_word': start,\n",
    "                    'end_word': start + window_size,\n",
    "                    'function': func,\n",
    "                    'similarity': similarity\n",
    "                })\n",
    "\n",
    "                results.append(result)\n",
    "\n",
    "print(\"Sliding window embedding analysis complete.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c4f3d5ee-4470-40a6-8a26-5a50bfc245c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../Data/embedding_flow_similarity.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# Save Results\n",
    "# --------------------------------------------------------------------\n",
    "similarity_df = pd.DataFrame(results)\n",
    "similarity_df.to_csv('../Data/embedding_flow_similarity.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Results saved to ../Data/embedding_flow_similarity.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
