{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2634594-3920-415a-a925-10d7548e38e2",
   "metadata": {},
   "source": [
    "# LLM Reference Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d17d3be5-4339-438c-bce9-78ea22b8dfcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 1. Import necessary libraries\n",
    "# --------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526de661-9af8-455f-a329-0dfaf1bc75c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 2. Setup\n",
    "# --------------------------------------------------------------------\n",
    "client = InferenceClient(\n",
    "    provider=\"together\",\n",
    "    api_key=\"REPLACE WITH YOUR KEY\",\n",
    ")\n",
    "\n",
    "LLAMA_MODEL = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "temperature = 1\n",
    "top_p = 1\n",
    "max_tokens = 500\n",
    "n = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d64dbb8-08ab-4247-af8a-ec597e81f507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 3. Load your data_long\n",
    "# --------------------------------------------------------------------\n",
    "data_long = pd.read_csv('../Data/data_long.csv', encoding='utf-8-sig')\n",
    "questions_data = data_long[data_long['subject_id'] == 1].sort_values('question').head(10)\n",
    "questions_data['correct_answer'] = questions_data['correct_answer'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9824b745-e5a9-406c-ad1b-1c9e1cf86c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 4. Define Prompt Templates (Dictionary) - Clean Functional Prompts\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "prompt_templates = {\n",
    "\n",
    "    'control': \"\"\"You are simulating a participant thinking aloud while solving a reasoning problem.\n",
    "\n",
    "Here is the reasoning problem the participant is facing:\n",
    "\n",
    "{question_text}\n",
    "\n",
    "Your task is to generate 5 short example sentences that illustrate RESPONSE CONTROL.\n",
    "\n",
    "Response control refers to situations where the participant is inhibiting, rejecting, or resisting their first intuitive response.\n",
    "\n",
    "CRITICAL INSTRUCTION:\n",
    "Do NOT mention or refer to any specific content, numbers, names, or answers from the problem.\n",
    "Focus ONLY on the generic cognitive process of inhibiting or resisting an initial answer impulse.\n",
    "\n",
    "These sentences should sound like a real person trying to stop themselves from blurting out the first thing that came to mind.\n",
    "\n",
    "Generate exactly 5 sentences. Number them.\n",
    "\n",
    "Be concise and natural.\n",
    "\n",
    "Do not include any other text besides the 5 numbered sentences.\"\"\",\n",
    "\n",
    "    'generation': \"\"\"You are simulating a participant thinking aloud while solving a reasoning problem.\n",
    "\n",
    "Here is the reasoning problem the participant is facing:\n",
    "\n",
    "{question_text}\n",
    "\n",
    "Your task is to generate 5 short example sentences that illustrate RESPONSE GENERATION.\n",
    "\n",
    "Response generation refers to situations where the participant is actively searching for new possible answers, alternatives, or hypotheses.\n",
    "\n",
    "CRITICAL INSTRUCTION:\n",
    "Do NOT mention or refer to any specific content, numbers, names, or answers from the problem.\n",
    "Focus ONLY on the generic cognitive process of exploring options, generating alternatives, or mentally simulating scenarios.\n",
    "\n",
    "These sentences should sound like a real person searching for possible answers, exploring ideas, or trying to figure things out.\n",
    "\n",
    "Generate exactly 5 sentences. Number them.\n",
    "\n",
    "Be concise and natural.\n",
    "\n",
    "Do not include any other text besides the 5 numbered sentences.\"\"\",\n",
    "\n",
    "    'justification': \"\"\"You are simulating a participant thinking aloud while solving a reasoning problem.\n",
    "\n",
    "Here is the reasoning problem the participant is facing:\n",
    "\n",
    "{question_text}\n",
    "\n",
    "Your task is to generate 5 short example sentences that illustrate RESPONSE JUSTIFICATION.\n",
    "\n",
    "Response justification refers to situations where the participant is providing explicit reasons, arguments, or explanations to support the response they are currently considering.\n",
    "\n",
    "CRITICAL INSTRUCTION:\n",
    "Do NOT mention or refer to any specific content, numbers, names, or answers from the problem.\n",
    "Focus ONLY on the generic cognitive process of explaining, defending, or rationalizing an answer (whatever that answer may be).\n",
    "\n",
    "These sentences should sound like a real person giving reasons for why they believe their answer might be correct.\n",
    "\n",
    "Generate exactly 5 sentences. Number them.\n",
    "\n",
    "Be concise and natural.\n",
    "\n",
    "Do not include any other text besides the 5 numbered sentences.\"\"\",\n",
    "\n",
    "    'regulation': \"\"\"You are simulating a participant thinking aloud while solving a reasoning problem.\n",
    "\n",
    "Here is the reasoning problem the participant is facing:\n",
    "\n",
    "{question_text}\n",
    "\n",
    "Your task is to generate 5 short example sentences that illustrate RESPONSE REGULATION.\n",
    "\n",
    "Response regulation refers to situations where the participant is monitoring or reflecting on their own thinking process.\n",
    "\n",
    "CRITICAL INSTRUCTION:\n",
    "Do NOT mention or refer to any specific content, numbers, names, or answers from the problem.\n",
    "Focus ONLY on the generic cognitive process of reflecting on difficulty, uncertainty, effort allocation, or decisions about how to proceed.\n",
    "\n",
    "These sentences should sound like a real person thinking about their thinking, expressing hesitation, confidence, effort, or meta-reasoning.\n",
    "\n",
    "Generate exactly 5 sentences. Number them.\n",
    "\n",
    "Be concise and natural.\n",
    "\n",
    "Do not include any other text besides the 5 numbered sentences.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a89cbca7-62a1-4280-a153-f4bcdff8ad01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 5. Generate Prototypes Function\n",
    "# --------------------------------------------------------------------\n",
    "def generate_prototypes(question_row, function_type):\n",
    "    prompt = prompt_templates[function_type].format(\n",
    "        question_text=question_row['question_text'],\n",
    "        lured_answer=question_row['lured_answer'],\n",
    "        correct_answer=question_row['correct_answer']\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are simulating a participant thinking aloud in a reasoning task.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=LLAMA_MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,  # Adjust based on response length\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        n=n\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd631e4b-1cb9-441e-99b5-19f891b43a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CONTROL prototypes for Question 1...\n",
      "Generating GENERATION prototypes for Question 1...\n",
      "Generating JUSTIFICATION prototypes for Question 1...\n",
      "Generating REGULATION prototypes for Question 1...\n",
      "Generating CONTROL prototypes for Question 2...\n",
      "Generating GENERATION prototypes for Question 2...\n",
      "Generating JUSTIFICATION prototypes for Question 2...\n",
      "Generating REGULATION prototypes for Question 2...\n",
      "Generating CONTROL prototypes for Question 3...\n",
      "Generating GENERATION prototypes for Question 3...\n",
      "Generating JUSTIFICATION prototypes for Question 3...\n",
      "Generating REGULATION prototypes for Question 3...\n",
      "Generating CONTROL prototypes for Question 4...\n",
      "Generating GENERATION prototypes for Question 4...\n",
      "Generating JUSTIFICATION prototypes for Question 4...\n",
      "Generating REGULATION prototypes for Question 4...\n",
      "Generating CONTROL prototypes for Question 5...\n",
      "Generating GENERATION prototypes for Question 5...\n",
      "Generating JUSTIFICATION prototypes for Question 5...\n",
      "Generating REGULATION prototypes for Question 5...\n",
      "Generating CONTROL prototypes for Question 6...\n",
      "Generating GENERATION prototypes for Question 6...\n",
      "Generating JUSTIFICATION prototypes for Question 6...\n",
      "Generating REGULATION prototypes for Question 6...\n",
      "Generating CONTROL prototypes for Question 7...\n",
      "Generating GENERATION prototypes for Question 7...\n",
      "Generating JUSTIFICATION prototypes for Question 7...\n",
      "Generating REGULATION prototypes for Question 7...\n",
      "Generating CONTROL prototypes for Question 8...\n",
      "Generating GENERATION prototypes for Question 8...\n",
      "Generating JUSTIFICATION prototypes for Question 8...\n",
      "Generating REGULATION prototypes for Question 8...\n",
      "Generating CONTROL prototypes for Question 9...\n",
      "Generating GENERATION prototypes for Question 9...\n",
      "Generating JUSTIFICATION prototypes for Question 9...\n",
      "Generating REGULATION prototypes for Question 9...\n",
      "Generating CONTROL prototypes for Question 10...\n",
      "Generating GENERATION prototypes for Question 10...\n",
      "Generating JUSTIFICATION prototypes for Question 10...\n",
      "Generating REGULATION prototypes for Question 10...\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 6. Main Loop with Error Handling\n",
    "# --------------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "for idx, row in questions_data.iterrows():\n",
    "    for function in ['control', 'generation', 'justification', 'regulation']:\n",
    "        print(f\"Generating {function.upper()} prototypes for Question {row['question']}...\")\n",
    "        \n",
    "        success = False\n",
    "        attempts = 0\n",
    "        \n",
    "        while not success and attempts < 4:\n",
    "            try:\n",
    "                prototypes = generate_prototypes(row, function)\n",
    "                results.append({\n",
    "                    'subject_id': row['subject_id'],\n",
    "                    'question': row['question'],\n",
    "                    'function': function,\n",
    "                    'prototypes': prototypes\n",
    "                })\n",
    "                success = True  # Exit the retry loop\n",
    "                time.sleep(2)  # Be gentle with the API\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered: {e}. Waiting for 1 minute before retrying...\")\n",
    "                time.sleep(60)\n",
    "                attempts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f0824a9-27fb-41dc-a4e6-fdc6783122c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generated prototypes to ../Data/prototypes_llama3.3.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 7. Save Results\n",
    "# --------------------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('../Data/prototypes_llama3.3.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Saved generated prototypes to ../Data/prototypes_llama3.3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
