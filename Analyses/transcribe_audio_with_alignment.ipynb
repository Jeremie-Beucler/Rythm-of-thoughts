{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdf7e65-430f-46d9-8fdd-33934da35ef9",
   "metadata": {},
   "source": [
    "## Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f208c69-7aa7-4c5e-86b9-451a343c3241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import whisperx\n",
    "from tqdm import tqdm\n",
    "from whisperx.audio import load_audio\n",
    "from whisperx.alignment import load_align_model, align\n",
    "import json\n",
    "\n",
    "# Tell Python where to find ffmpeg installed via brew\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/opt/homebrew/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e38ecdff-8e67-41f7-93e0-a2c4e9ff1ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import data from Byrd et al., 2023 – Study 2\n",
    "data = pd.read_excel('../Data/Byrd_2023_Study_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23b2eb35-9d18-45a3-a223-8df1c4bbeb22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "root_dir = Path('../Data/Byrd_2023_Study_2_recordings/')\n",
    "\n",
    "# List of tuples (id, path)\n",
    "rows = []\n",
    "\n",
    "# Walk through all subdirectories and find .mp3 files\n",
    "for mp3_file in root_dir.rglob('*.mp3'):\n",
    "    file_id = mp3_file.stem.split('-')[0]  # Remove suffix after '-' from stem (no extension)\n",
    "    file_path = str(mp3_file.resolve())    # Absolute path\n",
    "    rows.append((file_id, file_path))\n",
    "\n",
    "# Create DataFrame\n",
    "audio_data = pd.DataFrame(rows, columns=['id', 'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c0595-9256-49b8-9d25-fb555c7d7c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment the next line to only process the first 5 files (for testing)\n",
    "#audio_data = pd.DataFrame(rows, columns=['id','path']).head(5)  # test first 5\n",
    "\n",
    "# Device & model dtype\n",
    "device       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if torch.cuda.is_available() else \"float32\"\n",
    "\n",
    "# Load ASR model\n",
    "print(\"Loading WhisperX model…\")\n",
    "model = whisperx.load_model(\n",
    "    \"deepdml/faster-whisper-large-v3-turbo-ct2\",\n",
    "    device,\n",
    "    compute_type=compute_type,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "# Load alignment model\n",
    "print(\"Loading alignment model…\")\n",
    "align_model, metadata = load_align_model(language_code=\"en\", device=device)\n",
    "\n",
    "# Prepare storage & timers\n",
    "transcriptions   = []\n",
    "all_word_segments = []\n",
    "backup_every     = 50\n",
    "output_file      = \"../Data/audio_data_with_transcriptions_and_alignment.pkl\"\n",
    "start            = time.time()\n",
    "\n",
    "for idx, path in enumerate(tqdm(audio_data['path'], desc=\"Files\", unit=\"file\")):\n",
    "    print(f\"\\n---\\nFile {idx+1}/{len(audio_data)}: {path}\")\n",
    "    try:\n",
    "        # 1) Load audio\n",
    "        audio = load_audio(path)         # np.ndarray @ 16 kHz\n",
    "\n",
    "        # 2) ASR\n",
    "        result   = model.transcribe(audio, 16000)\n",
    "        segments = result[\"segments\"]    # List[dict]\n",
    "\n",
    "        # 3) Join text\n",
    "        text = \" \".join(s[\"text\"] for s in segments)\n",
    "        transcriptions.append(text)\n",
    "\n",
    "        # 4) Forced alignment (word timestamps)\n",
    "        word_segments = align(\n",
    "            segments,      # transcript\n",
    "            align_model,   # model\n",
    "            metadata,      # metadata dict\n",
    "            audio,         # waveform\n",
    "            device=device  # cpu / cuda\n",
    "        )\n",
    "        all_word_segments.append(word_segments[\"word_segments\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\" ERROR:\", e)\n",
    "        transcriptions.append(None)\n",
    "        all_word_segments.append(None)\n",
    "\n",
    "    # Backup\n",
    "    if (idx+1) % backup_every == 0:\n",
    "        df = audio_data.loc[:idx].copy()\n",
    "        df['transcription']  = transcriptions\n",
    "        df['word_segments']  = all_word_segments\n",
    "        df.to_pickle(f\"backup_{os.path.basename(output_file)}\")\n",
    "\n",
    "# Final save\n",
    "audio_data['transcription']   = transcriptions\n",
    "audio_data['word_segments']   = all_word_segments\n",
    "audio_data.to_pickle(output_file)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"\\nDone in {elapsed/60:.2f} min; avg {elapsed/len(audio_data):.2f}s/file\")\n",
    "print(\"Saved to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb571c42-dadd-4313-af73-14fcc893856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = pd.read_pickle(\"../Data/audio_data_with_transcriptions_and_alignment.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02e9a52e-8c25-4bc0-8f32-889fdb464e70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚨 Faulty transcription detected:\n",
      " Which sentence is correct? A, B, R, Y, B, U, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z.\n",
      "--------------------------------------------------\n",
      "\n",
      "🚨 Faulty transcription detected:\n",
      " Mary's father has five daughters, but no sons. Nana, Nini, Nini, Nono. What is the fifth daughter's name, probably? This looks like right away vowels, so A-E-I-O-U. So I would guess the fifth daughter's name is Nunu. This actually made me think of a...  a kid's song from when I was a kid by a Canadian singer called Fred Penner, and he had a song called Bananas and Benonos, so it went through the vowels. It was like, A, like, T, A, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,  New news.\n",
      "--------------------------------------------------\n",
      "\n",
      "🚨 Faulty transcription detected:\n",
      " In a one-story pink house, there was a pink person, a pink cat, a pink fish, pink computer, a pink chair, a pink table, a pink telephone, a pink shower. Everything was pink. What color were the stairs, probably? Um...  Okay, so right away, I think the trick in this is it's a one-story house, so there are no stairs. Yeah, there wouldn't be stairs, so they wouldn't have a color. And I guess the question just tried to confuse you by saying pink, pink, pink, pink, pink, pink, pink, pink, pink, so that your brain automatically went to pink. So I will put  There were no stairs.\n",
      "--------------------------------------------------\n",
      "\n",
      "🚨 Faulty transcription detected:\n",
      " Mary's father has five daughters, but no sons. Nana, Nene, Nene, Nono. What is the fifth daughter's name? Probably. Please remember to read out loud and say everything that comes to mind. Nana, Nene, Nene, Nono.  No, no, no, no, no, no, no. No, no? Is there a right answer for this? No, no.\n",
      "--------------------------------------------------\n",
      "\n",
      "🚨 Faulty transcription detected:\n",
      " Mary's father has five daughters but no sons. Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na Na\n",
      "--------------------------------------------------\n",
      "🧹 Skipped 5 row(s) during creation due to faulty transcriptions.\n",
      "✅ Cleaned data saved to ../Data/data_long.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/b5p5c0ld0yl62qv53ljbbdtc0000gp/T/ipykernel_44111/1785576372.py:137: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_long['familiar'] = data_long['familiar'].fillna(0).replace({'Y': 1}).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# --- Clean checker ---\n",
    "def check_cleaning(text):\n",
    "    if not isinstance(text, str):\n",
    "        return False  # Skip non-string entries\n",
    "\n",
    "    # Match words repeated 8+ times, separated by any non-word characters (space, comma, etc.)\n",
    "    pattern_words = r'\\b(\\w+)([\\W_]+\\1){7,}\\b'\n",
    "    pattern_letters = r'\\b(\\w)([\\W_]+\\1){7,}\\b'\n",
    "\n",
    "    if re.search(pattern_words, text, flags=re.IGNORECASE) or re.search(pattern_letters, text, flags=re.IGNORECASE):\n",
    "        print(\"\\nFaulty transcription detected:\")\n",
    "        print(text)\n",
    "        print(\"-\" * 50)\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# --- Load audio file paths ---\n",
    "rows = []\n",
    "for mp3_file in root_dir.rglob('*.mp3'):\n",
    "    file_id = mp3_file.stem.split('-')[0]\n",
    "    file_path = str(mp3_file.resolve())\n",
    "    rows.append((file_id, file_path))\n",
    "audio_paths = pd.DataFrame(rows, columns=['id', 'path'])\n",
    "\n",
    "# --- Ethnicity mapping ---\n",
    "ethnicity_map = {\n",
    "    1: 'American Indian or Native American',\n",
    "    2: 'Pacific Islander',\n",
    "    3: 'White',\n",
    "    4: 'Black',\n",
    "    5: 'Hispanic or Latino'\n",
    "}\n",
    "\n",
    "# --- Prepare rows ---\n",
    "rows = []\n",
    "demographic_cols = ['Age', 'Gender', 'Household Income', 'Familiar']\n",
    "audio_cols = [col for col in data.columns if col.endswith(' Audio')]\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    subject_id = idx + 1\n",
    "    ethnicity = ethnicity_map.get(row['Q21 Data'], 'Other')\n",
    "\n",
    "    for q_num, audio_col in enumerate(audio_cols, start=1):\n",
    "        audio_pos = data.columns.get_loc(audio_col)\n",
    "        code_col = data.columns[audio_pos - 3]\n",
    "        response_col = data.columns[audio_pos - 2]\n",
    "        transcription_old_col = data.columns[audio_pos - 1]\n",
    "        d_col = data.columns[audio_pos + 1]\n",
    "        c_col = data.columns[audio_pos + 2]\n",
    "        lure_consideration_col = data.columns[audio_pos + 3]\n",
    "\n",
    "        audio_url = row[audio_col]\n",
    "        audio_id = None\n",
    "        if isinstance(audio_url, str) and 'play/' in audio_url:\n",
    "            audio_id = audio_url.split('play/')[1]\n",
    "\n",
    "        transcription_new = None\n",
    "        word_segments = None\n",
    "        mp3_path = None\n",
    "        if audio_id in audio_data['id'].values:\n",
    "            matched = audio_data.loc[audio_data['id'] == audio_id]\n",
    "            if 'transcription' in matched.columns:\n",
    "                transcription_new = matched.iloc[0]['transcription']\n",
    "            if 'word_segments' in matched.columns:\n",
    "                word_segments = matched.iloc[0]['word_segments']\n",
    "            mp3_path = audio_paths.loc[audio_paths['id'] == audio_id, 'path'].values[0] if audio_id in audio_paths['id'].values else None\n",
    "\n",
    "        # ❗ Skip faulty transcriptions\n",
    "        if check_cleaning(transcription_new):\n",
    "            continue\n",
    "\n",
    "        lure_consideration = 1 if row.get(lure_consideration_col) == 1 else 0\n",
    "\n",
    "        row_dict = {\n",
    "            'subject_id': subject_id,\n",
    "            'question': q_num,\n",
    "            'response': row.get(code_col, None),\n",
    "            'response_text': row.get(response_col, None),\n",
    "            'transcription_old': row.get(transcription_old_col, None),\n",
    "            'transcription_new': transcription_new,\n",
    "            'word_segments': word_segments,\n",
    "            'audio_url': audio_url,\n",
    "            'mp3_path': mp3_path,\n",
    "            'reconsidered_initial_resp': row.get(d_col, None),\n",
    "            'verbalized_reasons': row.get(c_col, None),\n",
    "            'lure_consideration': lure_consideration,\n",
    "            'ethnicity': ethnicity\n",
    "        }\n",
    "\n",
    "        for col in demographic_cols:\n",
    "            row_dict[col] = row[col]\n",
    "\n",
    "        rows.append(row_dict)\n",
    "\n",
    "# --- Create DataFrame ---\n",
    "data_long = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "# --- CRT Questions ---\n",
    "question_info = {\n",
    "    1: {\"question_text\": \"Mary’s father has 5 daughters but no sons—Nana, Nene, Nini, Nono. What is the fifth daughter’s name probably?\", \"correct_answer\": \"Mary\", \"lured_answer\": \"Nunu\"},\n",
    "    2: {\"question_text\": \"If you were running a race, and you passed the person in 2nd place, what place would you be in now?\", \"correct_answer\": \"2nd\", \"lured_answer\": \"1st\"},\n",
    "    3: {\"question_text\": \"It’s a stormy night and a plane crashes - in which country do you bury the survivors?\", \"correct_answer\": \"Don't bury survivors\", \"lured_answer\": \"Burial location\"},\n",
    "    4: {\"question_text\": \"A monkey, a squirrel, and a bird are racing to the top of a coconut tree. Who will get the banana first?\", \"correct_answer\": \"No banana on coconut tree\", \"lured_answer\": \"Any animal\"},\n",
    "    5: {\"question_text\": \"In a one-storey pink house with everything pink, what colour were the stairs probably?\", \"correct_answer\": \"No stairs\", \"lured_answer\": \"Pink\"},\n",
    "    6: {\"question_text\": \"How many of each animal did Moses put on the ark?\", \"correct_answer\": \"None\", \"lured_answer\": \"Two\"},\n",
    "    7: {\"question_text\": \"The wind blows west. An electric train runs east. In which direction does the smoke blow?\", \"correct_answer\": \"No smoke\", \"lured_answer\": \"West\"},\n",
    "    8: {\"question_text\": \"If you have only one match and you walk into a dark room with an oil lamp, a newspaper and wood—which thing would you light first?\", \"correct_answer\": \"Match\", \"lured_answer\": \"Oil lamp / Newspaper / Wood\"},\n",
    "    9: {\"question_text\": \"Would it be ethical for a man to marry the sister of his widow?\", \"correct_answer\": \"Not possible\", \"lured_answer\": \"Yes / No\"},\n",
    "    10: {\"question_text\": \"Which sentence is correct: (a) 'the yolk of the egg are white' or (b) 'the yolk of the egg is white'?\", \"correct_answer\": \"The yolk is yellow\", \"lured_answer\": \"b\"}\n",
    "}\n",
    "data_long['question_text'] = data_long['question'].map(lambda x: question_info[x]['question_text'])\n",
    "data_long['correct_answer'] = data_long['question'].map(lambda x: question_info[x]['correct_answer'])\n",
    "data_long['lured_answer'] = data_long['question'].map(lambda x: question_info[x]['lured_answer'])\n",
    "\n",
    "# --- Rename and reorder ---\n",
    "data_long = data_long.rename(columns={\n",
    "    'Age': 'age',\n",
    "    'Gender': 'gender',\n",
    "    'Household Income': 'household_income',\n",
    "    'Familiar': 'familiar'\n",
    "})\n",
    "\n",
    "column_order = [\n",
    "    'subject_id', 'question',\n",
    "    'question_text', 'correct_answer', 'lured_answer',\n",
    "    'response', 'response_text', 'transcription_old', 'transcription_new', 'word_segments',\n",
    "    'audio_url', 'mp3_path',\n",
    "    'reconsidered_initial_resp', 'verbalized_reasons', 'lure_consideration',\n",
    "    'ethnicity', 'age', 'gender', 'household_income', 'familiar'\n",
    "]\n",
    "data_long = data_long[column_order]\n",
    "\n",
    "# --- Clean booleans ---\n",
    "for col in ['reconsidered_initial_resp', 'verbalized_reasons']:\n",
    "    data_long[col] = data_long[col].replace({'Y': 1, 'N': 0})\n",
    "data_long['familiar'] = data_long['familiar'].fillna(0).replace({'Y': 1}).astype(int)\n",
    "\n",
    "# Step 1: Print how many rows were skipped\n",
    "total_possible = len(data) * len(audio_cols)\n",
    "final_count = len(data_long)\n",
    "removed_count = total_possible - final_count\n",
    "print(f\"Skipped {removed_count} row(s) during creation due to faulty transcriptions.\")\n",
    "\n",
    "# Step 4: Convert word_segments to JSON-safe string with native floats\n",
    "def clean_word_segments(segment_list):\n",
    "    if isinstance(segment_list, list):\n",
    "        return json.dumps([\n",
    "            {\n",
    "                \"word\": w[\"word\"],\n",
    "                \"start\": float(w[\"start\"]),\n",
    "                \"end\": float(w[\"end\"]),\n",
    "                \"score\": float(w[\"score\"])\n",
    "            } for w in segment_list\n",
    "        ])\n",
    "    return None\n",
    "\n",
    "data_long['word_segments'] = data_long['word_segments'].apply(clean_word_segments)\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame\n",
    "data_long.to_csv(\"../Data/data_long.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ Cleaned data saved to ../Data/data_long.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
